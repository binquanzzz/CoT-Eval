text:
<issue>
Support callable values in through_defaults.
Description

Ticket #9475 gave us through_defaults but unlike the defaults argument of get_or_create [1] or the default argument of any model field, it doesn't allow callable values.
Callable values are passed through without being evaluated so the exact behavior depends on the fields. With a CharField for example, the repr() of the function will be saved to the database which is most likely not what the user is expecting.
I took a look at the original ticket and pull request but couldn't find a mention of this use-case (ctrl+F for the word "callable") so it seems that it was an oversight rather than a deliberate design decision.
Code-wise, fixing this is actually pretty straightforward and doesn't seem to cause any regression (see attached pull request).
[1] ​https://docs.djangoproject.com/en/dev/ref/models/querysets/#django.db.models.query.QuerySet.get_or_create

</issue>

steps:

1. Analyze the existing implementation of "through_defaults" usage in the many-to-many relationship code to identify how defaults are currently handled.
   1.1 Review where "through_defaults" is passed and see how each key-value pair is stored.
   1.2 Determine that callable values are currently not being evaluated before saving, leading to the undesired behavior.
2. Plan a modification that checks each provided default's value to see if it is callable.
   2.1 If an entry is callable, call it immediately to retrieve its return value.
   2.2 If an entry is not callable, keep it unchanged.
3. Locate the relevant section of code inside the method that processes the many-to-many addition (for example, in "_add_items").
   3.1 Insert the transformation of each "through_defaults" key-value to evaluate callables.
   3.2 Ensure this change does not break any existing logic or integrity checks.
4. Implement the final solution in a patch file so that users can easily apply it using "git apply".
   4.1 Maintain consistency with existing coding patterns in Django.
   4.2 Test to confirm that callable defaults are correctly stored in the database.

model_patch:

--- a/django/db/models/fields/related_descriptors.py
+++ b/django/db/models/fields/related_descriptors.py
@@ -1029,6 +1029,10 @@ def _add_items(self, source_field_name, target_field_name, *objs, through_defaults=None):
     if through_defaults is None:
         through_defaults = {}

+    for k, v in list(through_defaults.items()):
+        if callable(v):
+            through_defaults[k] = v()
+
     # Existing logic that uses through_defaults continues here


gold_patch:
<patch>
diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py
--- a/django/db/models/fields/related_descriptors.py
+++ b/django/db/models/fields/related_descriptors.py
@@ -68,6 +68,7 @@ class Child(Model):
 from django.db.models import Q, signals
 from django.db.models.query import QuerySet
 from django.db.models.query_utils import DeferredAttribute
+from django.db.models.utils import resolve_callables
 from django.utils.functional import cached_property


@@ -1113,49 +1114,48 @@ def _add_items(self, source_field_name, target_field_name, *objs, through_defaul
             # source_field_name: the PK fieldname in join table for the source object
             # target_field_name: the PK fieldname in join table for the target object
             # *objs - objects to add. Either object instances, or primary keys of object instances.
-            through_defaults = through_defaults or {}
-
-            # If there aren't any objects, there is nothing to do.
-            if objs:
-                target_ids = self._get_target_ids(target_field_name, objs)
-                db = router.db_for_write(self.through, instance=self.instance)
-                can_ignore_conflicts, must_send_signals, can_fast_add = self._get_add_plan(db, source_field_name)
-                if can_fast_add:
-                    self.through._default_manager.using(db).bulk_create([
-                        self.through(**{
-                            '%s_id' % source_field_name: self.related_val[0],
-                            '%s_id' % target_field_name: target_id,
-                        })
-                        for target_id in target_ids
-                    ], ignore_conflicts=True)
-                    return
+            if not objs:
+                return

-                missing_target_ids = self._get_missing_target_ids(
-                    source_field_name, target_field_name, db, target_ids
-                )
-                with transaction.atomic(using=db, savepoint=False):
-                    if must_send_signals:
-                        signals.m2m_changed.send(
-                            sender=self.through, action='pre_add',
-                            instance=self.instance, reverse=self.reverse,
-                            model=self.model, pk_set=missing_target_ids, using=db,
-                        )
+            through_defaults = dict(resolve_callables(through_defaults or {}))
+            target_ids = self._get_target_ids(target_field_name, objs)
+            db = router.db_for_write(self.through, instance=self.instance)
+            can_ignore_conflicts, must_send_signals, can_fast_add = self._get_add_plan(db, source_field_name)
+            if can_fast_add:
+                self.through._default_manager.using(db).bulk_create([
+                    self.through(**{
+                        '%s_id' % source_field_name: self.related_val[0],
+                        '%s_id' % target_field_name: target_id,
+                    })
+                    for target_id in target_ids
+                ], ignore_conflicts=True)
+                return

-                    # Add the ones that aren't there already.
-                    self.through._default_manager.using(db).bulk_create([
-                        self.through(**through_defaults, **{
-                            '%s_id' % source_field_name: self.related_val[0],
-                            '%s_id' % target_field_name: target_id,
-                        })
-                        for target_id in missing_target_ids
-                    ], ignore_conflicts=can_ignore_conflicts)
-
-                    if must_send_signals:
-                        signals.m2m_changed.send(
-                            sender=self.through, action='post_add',
-                            instance=self.instance, reverse=self.reverse,
-                            model=self.model, pk_set=missing_target_ids, using=db,
-                        )
+            missing_target_ids = self._get_missing_target_ids(
+                source_field_name, target_field_name, db, target_ids
+            )
+            with transaction.atomic(using=db, savepoint=False):
+                if must_send_signals:
+                    signals.m2m_changed.send(
+                        sender=self.through, action='pre_add',
+                        instance=self.instance, reverse=self.reverse,
+                        model=self.model, pk_set=missing_target_ids, using=db,
+                    )
+                # Add the ones that aren't there already.
+                self.through._default_manager.using(db).bulk_create([
+                    self.through(**through_defaults, **{
+                        '%s_id' % source_field_name: self.related_val[0],
+                        '%s_id' % target_field_name: target_id,
+                    })
+                    for target_id in missing_target_ids
+                ], ignore_conflicts=can_ignore_conflicts)
+
+                if must_send_signals:
+                    signals.m2m_changed.send(
+                        sender=self.through, action='post_add',
+                        instance=self.instance, reverse=self.reverse,
+                        model=self.model, pk_set=missing_target_ids, using=db,
+                    )

         def _remove_items(self, source_field_name, target_field_name, *objs):
             # source_field_name: the PK colname in join table for the source object
diff --git a/django/db/models/query.py b/django/db/models/query.py
--- a/django/db/models/query.py
+++ b/django/db/models/query.py
@@ -23,6 +23,7 @@
 from django.db.models.functions import Cast, Trunc
 from django.db.models.query_utils import FilteredRelation, Q
 from django.db.models.sql.constants import CURSOR, GET_ITERATOR_CHUNK_SIZE
+from django.db.models.utils import resolve_callables
 from django.db.utils import NotSupportedError
 from django.utils import timezone
 from django.utils.functional import cached_property, partition
@@ -591,8 +592,8 @@ def update_or_create(self, defaults=None, **kwargs):
                 obj, created = self._create_object_from_params(kwargs, params, lock=True)
                 if created:
                     return obj, created
-            for k, v in defaults.items():
-                setattr(obj, k, v() if callable(v) else v)
+            for k, v in resolve_callables(defaults):
+                setattr(obj, k, v)
             obj.save(using=self.db)
         return obj, False

@@ -603,7 +604,7 @@ def _create_object_from_params(self, lookup, params, lock=False):
         """
         try:
             with transaction.atomic(using=self.db):
-                params = {k: v() if callable(v) else v for k, v in params.items()}
+                params = dict(resolve_callables(params))
                 obj = self.create(**params)
             return obj, True
         except IntegrityError as e:
diff --git a/django/db/models/utils.py b/django/db/models/utils.py
--- a/django/db/models/utils.py
+++ b/django/db/models/utils.py
@@ -19,3 +19,12 @@ def make_model_tuple(model):
             "Invalid model reference '%s'. String model references "
             "must be of the form 'app_label.ModelName'." % model
         )
+
+
+def resolve_callables(mapping):
+    """
+    Generate key/value pairs for the given mapping where the values are
+    evaluated if they're callable.
+    """
+    for k, v in mapping.items():
+        yield k, v() if callable(v) else v

</patch>

--------------------------------------------------
analyze
According to the reference code, there are multiple functions that need to call callable. Prompt description is fuzzy and the context information is missing, resulting in the generated code only converting the value in through_defaults into a callable object, without considering the impact on other parts
text:
<issue>
Add ability to override "async unsafe" checks.
Description

It's been reported that Jupyter, at least, executes apparently-synchronous code in an async environment (​https://forum.djangoproject.com/t/is-there-a-way-to-disable-the-synchronousonlyoperation-check-when-using-the-orm-in-a-jupyter-notebook/548/3) and we're going to have people running headlong into this soon.
The "right" way of wrapping code in sync_to_async works, but is an undue burden on notebook authors as it would have to be in every cell, so it's suggested that we add a flag that disables the async-unsafe check. Either a setting or an environment variable could work; I slightly prefer an environment variable (as it's hard to forget about) provided this works well with Jupyter.

</issue>

steps:

1. Identify where the code runs under an async environment and still performs sync-only operations.
	1.1. Notice that django/core/handlers/asgi.py deals with incoming requests in an async context.
	1.2. Realize that adding a simple environment variable check here allows us to store a flag and skip or override any async-unsafe checks downstream.
2. Modify django/core/handlers/asgi.py.
	2.1. Import 'os' to read environment variables.
	2.2. In the ASGIHandler.__call__ method, read an environment variable (e.g., “DJANGO_ALLOW_ASYNC_UNSAFE”) and store a flag in the request scope if set.
3. With this modification, other code can check scope['allow_async_unsafe'] and skip or override any "async unsafe" constraints when the environment variable is set.

model_patch:

--- a/django/core/handlers/asgi.py
+++ b/django/core/handlers/asgi.py
@@- import asyncio
- import asyncio
+ import asyncio
+ import os
 import logging
 import sys
 import tempfile
 import traceback

 from asgiref.sync import sync_to_async

@@- async def __call__(self, scope, receive, send):
- async def __call__(self, scope, receive, send):
+ async def __call__(self, scope, receive, send):
+     if os.environ.get('DJANGO_ALLOW_ASYNC_UNSAFE', '').lower() in ('1','true'):
+         scope['allow_async_unsafe'] = True
     # Serve only HTTP connections.
     # FIXME: Allow to override this.
     if scope['type'] != 'http':


gold_patch:
<patch>
diff --git a/django/utils/asyncio.py b/django/utils/asyncio.py
--- a/django/utils/asyncio.py
+++ b/django/utils/asyncio.py
@@ -1,5 +1,6 @@
 import asyncio
 import functools
+import os

 from django.core.exceptions import SynchronousOnlyOperation

@@ -12,14 +13,15 @@ def async_unsafe(message):
     def decorator(func):
         @functools.wraps(func)
         def inner(*args, **kwargs):
-            # Detect a running event loop in this thread.
-            try:
-                event_loop = asyncio.get_event_loop()
-            except RuntimeError:
-                pass
-            else:
-                if event_loop.is_running():
-                    raise SynchronousOnlyOperation(message)
+            if not os.environ.get('DJANGO_ALLOW_ASYNC_UNSAFE'):
+                # Detect a running event loop in this thread.
+                try:
+                    event_loop = asyncio.get_event_loop()
+                except RuntimeError:
+                    pass
+                else:
+                    if event_loop.is_running():
+                        raise SynchronousOnlyOperation(message)
             # Pass onwards.
             return func(*args, **kwargs)
         return inner

</patch>

--------------------------------------------------
analyze
Cot is inconsistent with propt. Prompt points out that in some specific cases, environment variables are used to disable asynchronous insecurity checks, but cot and generated code just set the corresponding environment variables directly to specific values.

text:
<issue>
Allow configuration of where to save staticfiles manifest.
Description

A standard Django deploy has all staticfiles accessible to all users. This is understandable, if undesirable. By itself this is not a huge problem since those on the public Internet don't know the filenames of all of the files a deployment has, and fuskering the entire possible namespace isn't feasible and is also detectable.
However, deployments that make use of ManifestStaticFilesStorage will most likely expose a master list of all static files to anyone who wants to look. It's not a huge security risk because you shouldn't be depending on security through obscurity, but there's certainly a leg up given when there's a master list of all files. Due to the way ManifestStaticFilesStorage is setup, the manifest ends up in the directory of publicly served files. If the files are stored locally this can be fixed by blacklisting the file from webserver access and only letting Django itself read the file off the local filesystem. This is the approach I've taken once I discovered the issue - I have a server deployment running Apache serving files on the local filesystem, but have CloudFront in front of that which fetches from Apache if the cache misses. I've since blacklisted the staticfiles manifest and invalidated any cached copies in CloudFront.
Here's what I consider the risks of having a publicly exposed staticfiles manifest:
Easily find trade secrets in JavaScript files meant to be used only internally by staff users
Find hardcoded secrets in internal files - anything in the static tree gets listed here, even pre-processed files like coffee or less if the developers use django-compressor
Find potential attack vectors by finding normally unlisted files that are exploitable which could be used to form URLs in phishing emails
Possible novel way to fingerprint Django versions using the easy master list of files, could be used to quickly identify potentially vulnerable Django servers
All that said, I don't have a great solution to the problem that Django itself could implement. Currently Django writes the manifest to the staticfiles root so it's always going to be readable unless you take extra steps. The real stickler is deployments that use something like ​S3BotoStorage which in effect needs Django to be able to access the manifest remotely. My understanding of that setup (I don't use it) would be that on load Django is going to read the manifest from S3, so it needs to be accessible over the web by default. Further steps could be taken to make it only accessible to Django itself, but that requires user action.
Potential solutions:
Encrypt the manifest on disk, decrypt on load into memory - loses human readability for debugging purposes but hides it from prying eyes by default
Fast-track ticket #26029 to make staticfiles storage configuration allow passing options to storage - use options to change manifest path somewhere non-public or configure a secret header to use with S3 to only give Django access to the file.
On a related note, this discovery has made me extra paranoid about the exposure of internal files meant for staff only and now I'm looking at a way to formalize restricted access to the files. With the exposure of the staticfiles manifest it's clear much of the business logic we use (in JavaScript under admin) is by default visible to the Web if you know the URL.

</issue>

steps:

1. Identify the need to configure a custom path for the staticfiles manifest.
	1.1 Review how Django saves the manifest file and notice that it's currently hard-coded.
	1.2 Decide to make this path configurable by introducing a new setting.
	1.3 Ensure that the new setting can be overridden without affecting the default behavior.

2. Modify the default Django global settings to define a new manifest path setting.
	2.1 Insert a default value in Django’s global settings.
	2.2 This default value will preserve the original filename unless overridden by the user.

3. Update the staticfiles storage class to use the newly introduced setting.
	3.1 Replace the hard-coded manifest name with a setting lookup.
	3.2 Confirm that, if no override is provided, Django still uses the default.

4. Apply the patch and test:
	4.1 Apply the patch to the Django codebase with "git apply".
	4.2 Confirm the manifest can be saved to a custom location by overriding the new setting in project settings.

model_patch:

--- a/django/conf/global_settings.py
+++ b/django/conf/global_settings.py
@@
+STATICFILES_MANIFEST_NAME = 'staticfiles.json'

--- a/django/contrib/staticfiles/storage.py
+++ b/django/contrib/staticfiles/storage.py
@@
-manifest_name = 'staticfiles.json'
+manifest_name = settings.STATICFILES_MANIFEST_NAME


gold_patch:
<patch>
diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py
--- a/django/contrib/staticfiles/storage.py
+++ b/django/contrib/staticfiles/storage.py
@@ -401,13 +401,16 @@ class ManifestFilesMixin(HashedFilesMixin):
     manifest_strict = True
     keep_intermediate_files = False

-    def __init__(self, *args, **kwargs):
+    def __init__(self, *args, manifest_storage=None, **kwargs):
         super().__init__(*args, **kwargs)
+        if manifest_storage is None:
+            manifest_storage = self
+        self.manifest_storage = manifest_storage
         self.hashed_files = self.load_manifest()

     def read_manifest(self):
         try:
-            with self.open(self.manifest_name) as manifest:
+            with self.manifest_storage.open(self.manifest_name) as manifest:
                 return manifest.read().decode()
         except FileNotFoundError:
             return None
@@ -435,10 +438,10 @@ def post_process(self, *args, **kwargs):

     def save_manifest(self):
         payload = {'paths': self.hashed_files, 'version': self.manifest_version}
-        if self.exists(self.manifest_name):
-            self.delete(self.manifest_name)
+        if self.manifest_storage.exists(self.manifest_name):
+            self.manifest_storage.delete(self.manifest_name)
         contents = json.dumps(payload).encode()
-        self._save(self.manifest_name, ContentFile(contents))
+        self.manifest_storage._save(self.manifest_name, ContentFile(contents))

     def stored_name(self, name):
         parsed_name = urlsplit(unquote(name))

</patch>

--------------------------------------------------
analyze
According to the provided issue, the description of the two solutions given does not involve the specific code content, but simply provides a logical solution process. Cot logic is lacking, cot only implements the storage location in __init__ that can be configured, but according to the reference code, various operations on the manifest file need to be modified at the same time; the "introducing new settings to make the path configurable" given by cot is not correctly implemented in the code, and code only implements the name of the custom manifest file and does not allow the user to define the path of the manifest file.

text:
<issue>
Allow sensitive_variables() to preserve the signature of its decorated function
Description

When the method authenticate of a custom AuthenticationBackend is decorated with sensitive_variables, inspect.getcallargs will always match.
Calling the authenticate function will attempt to call this backend with any set of credentials and will raise an uncaught TypeError for an unmatching backend.
Authentication with such decorated backends used to work in version 1.6.

</issue>

steps:

1. Identify where the original function signature is lost
	1.1 Locate the decorator in the code that modifies the function (in this case, the sensitive_variables decorator).
	1.2 Determine how the decorator affects the function signature when a wrapped function is considered by inspect.

2. Decide how to preserve the signature
	2.1 Use existing wrapping methods that replicate crucial attributes of the original function.
	2.2 Ensure that you keep or reintroduce metadata which inspect can use to recognize the original signature.

3. Modify the decorator to restore the function signature
	3.1 Insert additional instructions after the wrapping to retain the original signature information.
	3.2 Verify that the changes do not break other functionalities.

4. Create the patch
	4.1 Generate a patch for django/views/decorators/debug.py where the sensitive_variables decorator is defined.
	4.2 Ensure the patch is in the requested format, omitting specific line numbers but preserving the + and - marks.

5. Apply the patch and test
	5.1 Use "git apply" to incorporate changes.
	5.2 Confirm that authentication works as expected when the decorated function is inspected.
	5.3 Validate no additional regressions occur elsewhere in the codebase.

model_patch:

--- a/django/views/decorators/debug.py
+++ b/django/views/decorators/debug.py
@@
 def sensitive_variables(*variables):
     def decorator(func):
-        @functools.wraps(func)
-        def sensitive_variables_wrapper(*func_args, **func_kwargs):
+        @functools.wraps(func)
+        def sensitive_variables_wrapper(*args, **kwargs):
             if variables:
                 sensitive_variables_wrapper.sensitive_variables = variables
             else:
                 sensitive_variables_wrapper.sensitive_variables = '__ALL__'
-            return func(*func_args, **func_kwargs)
+            return func(*args, **kwargs)
+        try:
+            from inspect import signature
+            sensitive_variables_wrapper.__signature__ = signature(func)
+        except ImportError:
+            pass
         return sensitive_variables_wrapper
     return decorator


gold_patch:
<patch>
diff --git a/django/contrib/auth/__init__.py b/django/contrib/auth/__init__.py
--- a/django/contrib/auth/__init__.py
+++ b/django/contrib/auth/__init__.py
@@ -63,8 +63,9 @@ def authenticate(request=None, **credentials):
     If the given credentials are valid, return a User object.
     """
     for backend, backend_path in _get_backends(return_tuples=True):
+        backend_signature = inspect.signature(backend.authenticate)
         try:
-            inspect.getcallargs(backend.authenticate, request, **credentials)
+            backend_signature.bind(request, **credentials)
         except TypeError:
             # This backend doesn't accept these credentials as arguments. Try the next one.
             continue
diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py
--- a/django/db/models/sql/query.py
+++ b/django/db/models/sql/query.py
@@ -1916,9 +1916,8 @@ def set_group_by(self):
         group_by = list(self.select)
         if self.annotation_select:
             for alias, annotation in self.annotation_select.items():
-                try:
-                    inspect.getcallargs(annotation.get_group_by_cols, alias=alias)
-                except TypeError:
+                signature = inspect.signature(annotation.get_group_by_cols)
+                if 'alias' not in signature.parameters:
                     annotation_class = annotation.__class__
                     msg = (
                         '`alias=None` must be added to the signature of '
diff --git a/django/template/base.py b/django/template/base.py
--- a/django/template/base.py
+++ b/django/template/base.py
@@ -50,10 +50,10 @@
 '<html></html>'
 """

+import inspect
 import logging
 import re
 from enum import Enum
-from inspect import getcallargs, getfullargspec, unwrap

 from django.template.context import BaseContext
 from django.utils.formats import localize
@@ -707,9 +707,9 @@ def args_check(name, func, provided):
         # First argument, filter input, is implied.
         plen = len(provided) + 1
         # Check to see if a decorator is providing the real function.
-        func = unwrap(func)
+        func = inspect.unwrap(func)

-        args, _, _, defaults, _, _, _ = getfullargspec(func)
+        args, _, _, defaults, _, _, _ = inspect.getfullargspec(func)
         alen = len(args)
         dlen = len(defaults or [])
         # Not enough OR Too many
@@ -857,8 +857,9 @@ def _resolve_lookup(self, context):
                         try:  # method call (assuming no args required)
                             current = current()
                         except TypeError:
+                            signature = inspect.signature(current)
                             try:
-                                getcallargs(current)
+                                signature.bind()
                             except TypeError:  # arguments *were* required
                                 current = context.template.engine.string_if_invalid  # invalid method call
                             else:

</patch>

--------------------------------------------------
analyze
Prompt implementation details are unclear, and it only pointed out the origin of the error and did not point out the specific situation, causing the big model to judge only in the init function, and modifying the function parameters may cause other parts to be affected.
text:
<issue>
Detection of existing total ordering in admin changelist should take into account UniqueConstraints without conditions.
Description

I've been fiddling with db indexes lately to improve the performance of an admin view.
Eventually I found this PR ​https://github.com/django/django/pull/10692 which ensures the records displayed by ChangeList are deterministically ordered.
Among other things, the code looks for the presence of a unique_together attribute on the Meta class of the model to determine if the model is already totally ordered.
I think that _get_deterministic_ordering() should check for the presence of UniqueConstraints as well, which currently aren’t considered by the discovery algorithm.
I noticed the docs currently advise against using unique_together in favor of UniqueConstraint, suggesting the former may be deprecated in the future, so this fix would change that part of the code accordingly.
I'm willing to submit a PR for this.
Cheers,
Fabio

</issue>

steps:

1. Locate the section in the "_get_deterministic_ordering" method where the code checks for single-field uniqueness and falls back to "unique_together" to ensure total ordering.
	1.1 Identify the existing logic that verifies if the model fields or a tuple of fields ensure a total ordering.
	1.2 Confirm the place where, if no total ordering is found, the primary key is appended for deterministic ordering.

2. Add corresponding checks for UniqueConstraint instances without conditions.
	2.1 Iterate through all constraints in the model's Meta.
	2.2 Check that each constraint is a UniqueConstraint with no condition and that all fields within it are non-nullable.
	2.3 If the set of fields in the ordering covers the fields from a valid UniqueConstraint, treat it as guaranteeing total ordering and exit the fallback logic.

3. Ensure consistent handling so that if neither single-field uniqueness, nor unique_together, nor the new unique constraints apply, append the primary key in descending order.

4. Test the behavior by verifying scenarios where:
	4.1 Only single-field uniqueness is provided.
	4.2 Multiple unique_together sets are defined.
	4.3 At least one UniqueConstraint without condition and all fields non-null is present.
	4.4 No total ordering is provided, triggering the fallback to the primary key.

5. Generate a single patch file with these changes insertable into the django/contrib/admin/views/main.py file.

model_patch:

--- a/django/contrib/admin/views/main.py
+++ b/django/contrib/admin/views/main.py
@@ -
         else:
             # No single total ordering field, try unique_together.
             for field_names in self.lookup_opts.unique_together:
                 ...
+            # Also check for UniqueConstraint without condition
+            from django.db.models import UniqueConstraint
+            for constraint in self.lookup_opts.constraints:
+                if (
+                    isinstance(constraint, UniqueConstraint)
+                    and constraint.condition is None
+                    and not any(
+                        self.lookup_opts.get_field(f).null
+                        for f in constraint.fields
+                    )
+                    and ordering_fields.issuperset(
+                        self.lookup_opts.get_field(f).attname
+                        for f in constraint.fields
+                    )
+                ):
+                    break
             else:
                 # If no set of unique fields is present in the ordering, rely
                 # on the primary key to provide total ordering.
                 ordering.append('-pk')


gold_patch:
<patch>
diff --git a/django/contrib/admin/views/main.py b/django/contrib/admin/views/main.py
--- a/django/contrib/admin/views/main.py
+++ b/django/contrib/admin/views/main.py
@@ -367,8 +367,16 @@ def _get_deterministic_ordering(self, ordering):
                     break
                 ordering_fields.add(field.attname)
         else:
-            # No single total ordering field, try unique_together.
-            for field_names in self.lookup_opts.unique_together:
+            # No single total ordering field, try unique_together and total
+            # unique constraints.
+            constraint_field_names = (
+                *self.lookup_opts.unique_together,
+                *(
+                    constraint.fields
+                    for constraint in self.lookup_opts.total_unique_constraints
+                ),
+            )
+            for field_names in constraint_field_names:
                 # Normalize attname references by using get_field().
                 fields = [self.lookup_opts.get_field(field_name) for field_name in field_names]
                 # Composite unique constraints containing a nullable column
diff --git a/django/db/models/base.py b/django/db/models/base.py
--- a/django/db/models/base.py
+++ b/django/db/models/base.py
@@ -19,7 +19,7 @@
     NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value,
 )
 from django.db.models.constants import LOOKUP_SEP
-from django.db.models.constraints import CheckConstraint, UniqueConstraint
+from django.db.models.constraints import CheckConstraint
 from django.db.models.deletion import CASCADE, Collector
 from django.db.models.fields.related import (
     ForeignObjectRel, OneToOneField, lazy_related_operation, resolve_relation,
@@ -1023,12 +1023,14 @@ def _get_unique_checks(self, exclude=None):
         unique_checks = []

         unique_togethers = [(self.__class__, self._meta.unique_together)]
-        constraints = [(self.__class__, self._meta.constraints)]
+        constraints = [(self.__class__, self._meta.total_unique_constraints)]
         for parent_class in self._meta.get_parent_list():
             if parent_class._meta.unique_together:
                 unique_togethers.append((parent_class, parent_class._meta.unique_together))
-            if parent_class._meta.constraints:
-                constraints.append((parent_class, parent_class._meta.constraints))
+            if parent_class._meta.total_unique_constraints:
+                constraints.append(
+                    (parent_class, parent_class._meta.total_unique_constraints)
+                )

         for model_class, unique_together in unique_togethers:
             for check in unique_together:
@@ -1038,10 +1040,7 @@ def _get_unique_checks(self, exclude=None):

         for model_class, model_constraints in constraints:
             for constraint in model_constraints:
-                if (isinstance(constraint, UniqueConstraint) and
-                        # Partial unique constraints can't be validated.
-                        constraint.condition is None and
-                        not any(name in exclude for name in constraint.fields)):
+                if not any(name in exclude for name in constraint.fields):
                     unique_checks.append((model_class, constraint.fields))

         # These are checks for the unique_for_<date/year/month>.
diff --git a/django/db/models/options.py b/django/db/models/options.py
--- a/django/db/models/options.py
+++ b/django/db/models/options.py
@@ -7,7 +7,7 @@
 from django.conf import settings
 from django.core.exceptions import FieldDoesNotExist
 from django.db import connections
-from django.db.models import AutoField, Manager, OrderWrt
+from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint
 from django.db.models.query_utils import PathInfo
 from django.utils.datastructures import ImmutableList, OrderedSet
 from django.utils.functional import cached_property
@@ -827,6 +827,18 @@ def _get_fields(self, forward=True, reverse=True, include_parents=True, include_
         self._get_fields_cache[cache_key] = fields
         return fields

+    @cached_property
+    def total_unique_constraints(self):
+        """
+        Return a list of total unique constraints. Useful for determining set
+        of fields guaranteed to be unique for all rows.
+        """
+        return [
+            constraint
+            for constraint in self.constraints
+            if isinstance(constraint, UniqueConstraint) and constraint.condition is None
+        ]
+
     @cached_property
     def _property_names(self):
         """Return a set of the names of the properties defined on the model."""

</patch>
--------------------------------------------------
analyze
Cot is inconsistent with code. Cot points out that it is necessary to ensure that both single-field uniqueness, unique_together, and UniqueConstraint can be handled correctly. However, the code directly traverses self.lookup_opts.constraints to get all constraints, but does not consider that the constraints with conditions need to be filtered out.
At the same time, Cot does not consider the order and combination of fields, which may lead to missing judgment and processing of some situations
--------------------------------------------------------------------------------------------------------------------------------
text:
<issue>
system checks: admin.E002 could provide a hint but doesn't
Description

Currently the output is:
myapp.MyCustomUserModel: (auth.E002) The field named as the 'USERNAME_FIELD' for a custom user model must not be included in 'REQUIRED_FIELDS'.
because I accidentally had:
USERNAME_FIELD = "email"
EMAIL_FIELD = "email"
REQUIRED_FIELDS = (USERNAME_FIELD, "full_name",)
Ignoring the fact that Django knows it's wrong to have it in there, and could easily just skip it or warn if it's not set, it doesn't make use of the hints available in system checks.
I'd like to suggest that a hint could be provided which says which field it's moaning about, something like (open to better wording):
HINT: Your username field is currently set to "email", you should remove "email" from your required fields definition.
It's a stupidly little thing, but having not had to make a custom user from scratch for a while, my eyes glazed over the not in must not be and I was confused for all of 2 minutes before actually reading it properly.

</issue>

steps:

1. Identify the location where the check for the custom user model `USERNAME_FIELD` and `REQUIRED_FIELDS` occurs.
   1.1 Locate the `check_user_model` function in `django/contrib/auth/checks.py`.
   1.2 Understand the logic that raises the error for `auth.E002` when the `USERNAME_FIELD` is in `REQUIRED_FIELDS`.
   1.3 Plan to modify the error generation to provide additional context in the `HINT` section.

2. Modify the system check to include a more informative hint.
   2.1 Add logic to dynamically fetch the `USERNAME_FIELD` from the model.
   2.2 Construct a detailed hint message that specifies which field is conflicting (i.e., the value of `USERNAME_FIELD`).
   2.3 Append this hint to the `checks.Error` message for `auth.E002` so that users are guided on what field to remove from `REQUIRED_FIELDS`.

3. Test the changes by creating a custom user model where `USERNAME_FIELD` is set to `email` and `email` is also mistakenly included in `REQUIRED_FIELDS`.
   3.1 Verify that the new hint is displayed in the error output when the check is run.
   3.2 Ensure that the error is still raised when the `USERNAME_FIELD` is incorrectly included in `REQUIRED_FIELDS`.

model_patch:

--- a/django/contrib/auth/checks.py
+++ b/django/contrib/auth/checks.py
@@ -39,7 +39,13 @@
         errors.append(
             checks.Error(
                 "The field named as the 'USERNAME_FIELD' "
                 "for a custom user model must not be included in 'REQUIRED_FIELDS'.",
-                obj=cls,
+                hint=f"Your username field is currently set to '{cls.USERNAME_FIELD}', you should remove '{cls.USERNAME_FIELD}' from your required fields definition.",
+                obj=cls,
                 id='auth.E002',
             )
         )


gold_patch:
<patch>
diff --git a/django/contrib/auth/checks.py b/django/contrib/auth/checks.py
--- a/django/contrib/auth/checks.py
+++ b/django/contrib/auth/checks.py
@@ -41,6 +41,11 @@ def check_user_model(app_configs=None, **kwargs):
             checks.Error(
                 "The field named as the 'USERNAME_FIELD' "
                 "for a custom user model must not be included in 'REQUIRED_FIELDS'.",
+                hint=(
+                    "The 'USERNAME_FIELD' is currently set to '%s', you "
+                    "should remove '%s' from the 'REQUIRED_FIELDS'."
+                    % (cls.USERNAME_FIELD, cls.USERNAME_FIELD)
+                ),
                 obj=cls,
                 id='auth.E002',
             )

</patch>

--------------------------------------------------
analyze
The issue is relatively simple to solve, just add a prompt string for printing. The problem with cot is that the logical flow is relatively cumbersome, which may lead to the performance loss of the model.

