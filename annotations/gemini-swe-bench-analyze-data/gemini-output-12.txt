text:
<issue>
Add the ability to define comments in table / columns
Description

		(last modified by Jared Chung)

Database-level comments are valuable for database administrators, data analysts, data scientists, and others who are looking to consume data that is managed by Django. Most Django-supported databases also support table-level and column-level comments. This ticket would add functionality to Django to allow Django users to specify comments for syncdb manage.py to enter into the database.
....
....
new proposal (kimsoungryoul : 2020.03.23)
We will develop the code such as below
class AModel(models.Model):
	 aaa = model.CharField(help_text="i am help_text", db_column_comment="i am db_comment",~~~)

	 class Meta:
		 db_table = "a_model_example_name"
		 db_table_comment ="this is a_model comment ~~~~"

</issue>

steps:

1. **Modify `django/core/management/commands/inspectdb.py` to retrieve and include table and column comments in the generated model code.**
    - Locate the `handle_inspection` method within the `Command` class.
    - After retrieving `table_description` in the table processing loop, add code to fetch table comments using `connection.introspection.get_table_comment(cursor, table_name)`.
    - Add code to fetch column comments using `connection.introspection.get_column_comments(cursor, table_name, column_names)` after the loop that iterates through `table_description` to gather column names.
    - In the section where the model `Meta` class is generated, add `db_table_comment = ...` if a table comment is retrieved.
    - Within the loop that iterates through `table_description` to generate field definitions, add `db_column_comment = ...` to the `extra_params` dictionary if a column comment is retrieved for the current column.

2. **Modify `django/db/backends/oracle/operations.py` to implement the introspection methods for retrieving table and column comments.**
    - Open `django/db/backends/oracle/operations.py` and locate the `DatabaseOperations` class.
    - Within `DatabaseOperations`, add a new class (or locate existing if it exists) for database introspection, typically named `DatabaseIntrospection`. If `DatabaseIntrospection` class exists, modify it, otherwise create it.
    - Inside the `DatabaseIntrospection` class, implement the `get_table_comment(self, cursor, table_name)` method. This method should execute a SQL query to fetch the comment from `USER_TAB_COMMENTS` for the given `table_name`.
    - Inside the `DatabaseIntrospection` class, implement the `get_column_comments(self, cursor, table_name, column_names)` method. This method should execute a SQL query to fetch comments from `USER_COL_COMMENTS` for the given `table_name` and `column_names`. Return a dictionary mapping column names to their comments.

3. **Generate the patch file.**
    - Use `diff -u` command (or similar diff tool) to compare the modified `inspectdb.py` and `oracle/operations.py` files with their original versions.
- Save the output of the `diff` command to a `.patch` file.

model_patch:

--- a/django/core/management/commands/inspectdb.py
+++ b/django/core/management/commands/inspectdb.py
@@ -125,6 +125,12 @@
                      table_description = connection.introspection.get_table_description(
                          cursor, table_name
                      )
+                    table_comment = connection.introspection.get_table_comment(
+                        cursor, table_name
+                    )
+                    column_comments = connection.introspection.get_column_comments(
+                        cursor, table_name
+                    )
                 except Exception as e:
                     yield "# Unable to inspect table '%s'" % table_name
                     yield "# The error was: %s" % e
@@ -146,6 +152,7 @@
                      )  # Holds Field notes, to be displayed in a Python comment.
                      extra_params = {}  # Holds Field parameters such as 'db_column'.
                      column_name = row.name
+                    column_comment = column_comments.get(column_name)
                      is_relation = column_name in relations

@@ -207,6 +214,9 @@
                          )
                          extra_params.update(field_params)
                          comment_notes.extend(field_notes)
+                        if column_comment:
+                            extra_params["db_column_comment"] = column_comment
+

                          field_type += "("

@@ -255,7 +265,7 @@
                      info.name == table_name and info.type == "p" for info in table_info
                  )
                  yield from self.get_meta(
-                     table_name, constraints, column_to_field_name, is_view, is_partition
+                    table_name, table_comment, constraints, column_to_field_name, is_view, is_partition
                  )

      def normalize_col_name(self, col_name, used_column_names, is_relation):
@@ -360,7 +370,7 @@
          return field_type, field_params, field_notes

      def get_meta(
-         self, table_name, constraints, column_to_field_name, is_view, is_partition
+         self, table_name, table_comment, constraints, column_to_field_name, is_view, is_partition
      ):
          """
          Return a sequence comprising the lines of code necessary
@@ -393,6 +403,8 @@
             "        managed = False%s" % managed_comment,
              "        db_table = %r" % table_name,
          ]
+        if table_comment:
+            meta += ["        db_table_comment = %r" % table_comment]
          if unique_together:
              tup = "(" + ", ".join(unique_together) + ",)"
              meta += ["        unique_together = %s" % tup]

--- a/django/db/backends/oracle/operations.py
+++ b/django/db/backends/oracle/operations.py
@@ -727,3 +727,33 @@
              )
          return True
          return False
+
+
+class DatabaseIntrospection(DatabaseOperations.DatabaseIntrospection):
+
+    def get_table_comment(self, cursor, table_name):
+        """
+        Retrieve comment for a table.
+        """
+        cursor.execute(
+            "SELECT comments FROM user_tab_comments WHERE table_name = %s",
+            [table_name.upper()],
+        )
+        row = cursor.fetchone()
+        if row:
+            return row[0]
+        return ""
+
+    def get_column_comments(self, cursor, table_name):
+        """
+        Retrieve comments for columns of a table.
+        """
+        cursor.execute(
+            "SELECT column_name, comments FROM user_col_comments WHERE table_name = %s",
+            [table_name.upper()],
+        )
+        return {
+            force_str(row[0]): force_str(row[1]) if row[1] else ""
+            for row in cursor.fetchall()
+        }
+
+DatabaseOperations.DatabaseIntrospection = DatabaseIntrospection
\ No newline at end of file


gold_patch:
<patch>
diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py
--- a/django/core/management/commands/inspectdb.py
+++ b/django/core/management/commands/inspectdb.py
@@ -78,18 +78,16 @@ def table2model(table_name):
             )
             yield "from %s import models" % self.db_module
             known_models = []
-            table_info = connection.introspection.get_table_list(cursor)
-
             # Determine types of tables and/or views to be introspected.
             types = {"t"}
             if options["include_partitions"]:
                 types.add("p")
             if options["include_views"]:
                 types.add("v")
+            table_info = connection.introspection.get_table_list(cursor)
+            table_info = {info.name: info for info in table_info if info.type in types}

-            for table_name in options["table"] or sorted(
-                info.name for info in table_info if info.type in types
-            ):
+            for table_name in options["table"] or sorted(name for name in table_info):
                 if table_name_filter is not None and callable(table_name_filter):
                     if not table_name_filter(table_name):
                         continue
@@ -232,6 +230,10 @@ def table2model(table_name):
                     if field_type.startswith(("ForeignKey(", "OneToOneField(")):
                         field_desc += ", models.DO_NOTHING"

+                    # Add comment.
+                    if connection.features.supports_comments and row.comment:
+                        extra_params["db_comment"] = row.comment
+
                     if extra_params:
                         if not field_desc.endswith("("):
                             field_desc += ", "
@@ -242,14 +244,22 @@ def table2model(table_name):
                     if comment_notes:
                         field_desc += "  # " + " ".join(comment_notes)
                     yield "    %s" % field_desc
-                is_view = any(
-                    info.name == table_name and info.type == "v" for info in table_info
-                )
-                is_partition = any(
-                    info.name == table_name and info.type == "p" for info in table_info
-                )
+                comment = None
+                if info := table_info.get(table_name):
+                    is_view = info.type == "v"
+                    is_partition = info.type == "p"
+                    if connection.features.supports_comments:
+                        comment = info.comment
+                else:
+                    is_view = False
+                    is_partition = False
                 yield from self.get_meta(
-                    table_name, constraints, column_to_field_name, is_view, is_partition
+                    table_name,
+                    constraints,
+                    column_to_field_name,
+                    is_view,
+                    is_partition,
+                    comment,
                 )

     def normalize_col_name(self, col_name, used_column_names, is_relation):
@@ -353,7 +363,13 @@ def get_field_type(self, connection, table_name, row):
         return field_type, field_params, field_notes

     def get_meta(
-        self, table_name, constraints, column_to_field_name, is_view, is_partition
+        self,
+        table_name,
+        constraints,
+        column_to_field_name,
+        is_view,
+        is_partition,
+        comment,
     ):
         """
         Return a sequence comprising the lines of code necessary
@@ -391,4 +407,6 @@ def get_meta(
         if unique_together:
             tup = "(" + ", ".join(unique_together) + ",)"
             meta += ["        unique_together = %s" % tup]
+        if comment:
+            meta += [f"        db_table_comment = {comment!r}"]
         return meta
diff --git a/django/db/backends/base/features.py b/django/db/backends/base/features.py
--- a/django/db/backends/base/features.py
+++ b/django/db/backends/base/features.py
@@ -334,6 +334,11 @@ class BaseDatabaseFeatures:
     # Does the backend support non-deterministic collations?
     supports_non_deterministic_collations = True

+    # Does the backend support column and table comments?
+    supports_comments = False
+    # Does the backend support column comments in ADD COLUMN statements?
+    supports_comments_inline = False
+
     # Does the backend support the logical XOR operator?
     supports_logical_xor = False

diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py
--- a/django/db/backends/base/schema.py
+++ b/django/db/backends/base/schema.py
@@ -141,6 +141,9 @@ class BaseDatabaseSchemaEditor:

     sql_delete_procedure = "DROP PROCEDURE %(procedure)s"

+    sql_alter_table_comment = "COMMENT ON TABLE %(table)s IS %(comment)s"
+    sql_alter_column_comment = "COMMENT ON COLUMN %(table)s.%(column)s IS %(comment)s"
+
     def __init__(self, connection, collect_sql=False, atomic=True):
         self.connection = connection
         self.collect_sql = collect_sql
@@ -289,6 +292,8 @@ def _iter_column_sql(
         yield column_db_type
         if collation := field_db_params.get("collation"):
             yield self._collate_sql(collation)
+        if self.connection.features.supports_comments_inline and field.db_comment:
+            yield self._comment_sql(field.db_comment)
         # Work out nullability.
         null = field.null
         # Include a default value, if requested.
@@ -445,6 +450,23 @@ def create_model(self, model):
         # definition.
         self.execute(sql, params or None)

+        if self.connection.features.supports_comments:
+            # Add table comment.
+            if model._meta.db_table_comment:
+                self.alter_db_table_comment(model, None, model._meta.db_table_comment)
+            # Add column comments.
+            if not self.connection.features.supports_comments_inline:
+                for field in model._meta.local_fields:
+                    if field.db_comment:
+                        field_db_params = field.db_parameters(
+                            connection=self.connection
+                        )
+                        field_type = field_db_params["type"]
+                        self.execute(
+                            *self._alter_column_comment_sql(
+                                model, field, field_type, field.db_comment
+                            )
+                        )
         # Add any field index and index_together's (deferred as SQLite
         # _remake_table needs it).
         self.deferred_sql.extend(self._model_indexes_sql(model))
@@ -614,6 +636,15 @@ def alter_db_table(self, model, old_db_table, new_db_table):
             if isinstance(sql, Statement):
                 sql.rename_table_references(old_db_table, new_db_table)

+    def alter_db_table_comment(self, model, old_db_table_comment, new_db_table_comment):
+        self.execute(
+            self.sql_alter_table_comment
+            % {
+                "table": self.quote_name(model._meta.db_table),
+                "comment": self.quote_value(new_db_table_comment or ""),
+            }
+        )
+
     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):
         """Move a model's table between tablespaces."""
         self.execute(
@@ -693,6 +724,18 @@ def add_field(self, model, field):
                 "changes": changes_sql,
             }
             self.execute(sql, params)
+        # Add field comment, if required.
+        if (
+            field.db_comment
+            and self.connection.features.supports_comments
+            and not self.connection.features.supports_comments_inline
+        ):
+            field_type = db_params["type"]
+            self.execute(
+                *self._alter_column_comment_sql(
+                    model, field, field_type, field.db_comment
+                )
+            )
         # Add an index, if required
         self.deferred_sql.extend(self._field_indexes_sql(model, field))
         # Reset connection if required
@@ -813,6 +856,11 @@ def _alter_field(
             self.connection.features.supports_foreign_keys
             and old_field.remote_field
             and old_field.db_constraint
+            and self._field_should_be_altered(
+                old_field,
+                new_field,
+                ignore={"db_comment"},
+            )
         ):
             fk_names = self._constraint_names(
                 model, [old_field.column], foreign_key=True
@@ -949,11 +997,15 @@ def _alter_field(
         # Type suffix change? (e.g. auto increment).
         old_type_suffix = old_field.db_type_suffix(connection=self.connection)
         new_type_suffix = new_field.db_type_suffix(connection=self.connection)
-        # Type or collation change?
+        # Type, collation, or comment change?
         if (
             old_type != new_type
             or old_type_suffix != new_type_suffix
             or old_collation != new_collation
+            or (
+                self.connection.features.supports_comments
+                and old_field.db_comment != new_field.db_comment
+            )
         ):
             fragment, other_actions = self._alter_column_type_sql(
                 model, old_field, new_field, new_type, old_collation, new_collation
@@ -1211,12 +1263,26 @@ def _alter_column_type_sql(
         an ALTER TABLE statement and a list of extra (sql, params) tuples to
         run once the field is altered.
         """
+        other_actions = []
         if collate_sql := self._collate_sql(
             new_collation, old_collation, model._meta.db_table
         ):
             collate_sql = f" {collate_sql}"
         else:
             collate_sql = ""
+        # Comment change?
+        comment_sql = ""
+        if self.connection.features.supports_comments and not new_field.many_to_many:
+            if old_field.db_comment != new_field.db_comment:
+                # PostgreSQL and Oracle can't execute 'ALTER COLUMN ...' and
+                # 'COMMENT ON ...' at the same time.
+                sql, params = self._alter_column_comment_sql(
+                    model, new_field, new_type, new_field.db_comment
+                )
+                if sql:
+                    other_actions.append((sql, params))
+            if new_field.db_comment:
+                comment_sql = self._comment_sql(new_field.db_comment)
         return (
             (
                 self.sql_alter_column_type
@@ -1224,12 +1290,27 @@ def _alter_column_type_sql(
                     "column": self.quote_name(new_field.column),
                     "type": new_type,
                     "collation": collate_sql,
+                    "comment": comment_sql,
                 },
                 [],
             ),
+            other_actions,
+        )
+
+    def _alter_column_comment_sql(self, model, new_field, new_type, new_db_comment):
+        return (
+            self.sql_alter_column_comment
+            % {
+                "table": self.quote_name(model._meta.db_table),
+                "column": self.quote_name(new_field.column),
+                "comment": self._comment_sql(new_db_comment),
+            },
             [],
         )

+    def _comment_sql(self, comment):
+        return self.quote_value(comment or "")
+
     def _alter_many_to_many(self, model, old_field, new_field, strict):
         """Alter M2Ms to repoint their to= endpoints."""
         # Rename the through table
@@ -1423,16 +1504,18 @@ def _field_indexes_sql(self, model, field):
             output.append(self._create_index_sql(model, fields=[field]))
         return output

-    def _field_should_be_altered(self, old_field, new_field):
+    def _field_should_be_altered(self, old_field, new_field, ignore=None):
+        ignore = ignore or set()
         _, old_path, old_args, old_kwargs = old_field.deconstruct()
         _, new_path, new_args, new_kwargs = new_field.deconstruct()
         # Don't alter when:
         # - changing only a field name
         # - changing an attribute that doesn't affect the schema
+        # - changing an attribute in the provided set of ignored attributes
         # - adding only a db_column and the column name is not changed
-        for attr in old_field.non_db_attrs:
+        for attr in ignore.union(old_field.non_db_attrs):
             old_kwargs.pop(attr, None)
-        for attr in new_field.non_db_attrs:
+        for attr in ignore.union(new_field.non_db_attrs):
             new_kwargs.pop(attr, None)
         return self.quote_name(old_field.column) != self.quote_name(
             new_field.column
diff --git a/django/db/backends/mysql/features.py b/django/db/backends/mysql/features.py
--- a/django/db/backends/mysql/features.py
+++ b/django/db/backends/mysql/features.py
@@ -18,6 +18,8 @@ class DatabaseFeatures(BaseDatabaseFeatures):
     requires_explicit_null_ordering_when_grouping = True
     atomic_transactions = False
     can_clone_databases = True
+    supports_comments = True
+    supports_comments_inline = True
     supports_temporal_subtraction = True
     supports_slicing_ordering_in_compound = True
     supports_index_on_text_field = False
diff --git a/django/db/backends/mysql/introspection.py b/django/db/backends/mysql/introspection.py
--- a/django/db/backends/mysql/introspection.py
+++ b/django/db/backends/mysql/introspection.py
@@ -5,18 +5,20 @@

 from django.db.backends.base.introspection import BaseDatabaseIntrospection
 from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo
-from django.db.backends.base.introspection import TableInfo
+from django.db.backends.base.introspection import TableInfo as BaseTableInfo
 from django.db.models import Index
 from django.utils.datastructures import OrderedSet

 FieldInfo = namedtuple(
-    "FieldInfo", BaseFieldInfo._fields + ("extra", "is_unsigned", "has_json_constraint")
+    "FieldInfo",
+    BaseFieldInfo._fields + ("extra", "is_unsigned", "has_json_constraint", "comment"),
 )
 InfoLine = namedtuple(
     "InfoLine",
     "col_name data_type max_len num_prec num_scale extra column_default "
-    "collation is_unsigned",
+    "collation is_unsigned comment",
 )
+TableInfo = namedtuple("TableInfo", BaseTableInfo._fields + ("comment",))


 class DatabaseIntrospection(BaseDatabaseIntrospection):
@@ -68,9 +70,18 @@ def get_field_type(self, data_type, description):

     def get_table_list(self, cursor):
         """Return a list of table and view names in the current database."""
-        cursor.execute("SHOW FULL TABLES")
+        cursor.execute(
+            """
+            SELECT
+                table_name,
+                table_type,
+                table_comment
+            FROM information_schema.tables
+            WHERE table_schema = DATABASE()
+            """
+        )
         return [
-            TableInfo(row[0], {"BASE TABLE": "t", "VIEW": "v"}.get(row[1]))
+            TableInfo(row[0], {"BASE TABLE": "t", "VIEW": "v"}.get(row[1]), row[2])
             for row in cursor.fetchall()
         ]

@@ -128,7 +139,8 @@ def get_table_description(self, cursor, table_name):
                 CASE
                     WHEN column_type LIKE '%% unsigned' THEN 1
                     ELSE 0
-                END AS is_unsigned
+                END AS is_unsigned,
+                column_comment
             FROM information_schema.columns
             WHERE table_name = %s AND table_schema = DATABASE()
             """,
@@ -159,6 +171,7 @@ def to_int(i):
                     info.extra,
                     info.is_unsigned,
                     line[0] in json_constraints,
+                    info.comment,
                 )
             )
         return fields
diff --git a/django/db/backends/mysql/schema.py b/django/db/backends/mysql/schema.py
--- a/django/db/backends/mysql/schema.py
+++ b/django/db/backends/mysql/schema.py
@@ -9,7 +9,7 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

     sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
     sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
-    sql_alter_column_type = "MODIFY %(column)s %(type)s%(collation)s"
+    sql_alter_column_type = "MODIFY %(column)s %(type)s%(collation)s%(comment)s"
     sql_alter_column_no_default_null = "ALTER COLUMN %(column)s SET DEFAULT NULL"

     # No 'CASCADE' which works as a no-op in MySQL but is undocumented
@@ -32,6 +32,9 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):

     sql_create_index = "CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s"

+    sql_alter_table_comment = "ALTER TABLE %(table)s COMMENT = %(comment)s"
+    sql_alter_column_comment = None
+
     @property
     def sql_delete_check(self):
         if self.connection.mysql_is_mariadb:
@@ -228,3 +231,11 @@ def _alter_column_type_sql(
     def _rename_field_sql(self, table, old_field, new_field, new_type):
         new_type = self._set_field_new_type_null_status(old_field, new_type)
         return super()._rename_field_sql(table, old_field, new_field, new_type)
+
+    def _alter_column_comment_sql(self, model, new_field, new_type, new_db_comment):
+        # Comment is alter when altering the column type.
+        return "", []
+
+    def _comment_sql(self, comment):
+        comment_sql = super()._comment_sql(comment)
+        return f" COMMENT {comment_sql}"
diff --git a/django/db/backends/oracle/features.py b/django/db/backends/oracle/features.py
--- a/django/db/backends/oracle/features.py
+++ b/django/db/backends/oracle/features.py
@@ -25,6 +25,7 @@ class DatabaseFeatures(BaseDatabaseFeatures):
     supports_partially_nullable_unique_constraints = False
     supports_deferrable_unique_constraints = True
     truncates_names = True
+    supports_comments = True
     supports_tablespaces = True
     supports_sequence_reset = False
     can_introspect_materialized_views = True
diff --git a/django/db/backends/oracle/introspection.py b/django/db/backends/oracle/introspection.py
--- a/django/db/backends/oracle/introspection.py
+++ b/django/db/backends/oracle/introspection.py
@@ -5,10 +5,13 @@
 from django.db import models
 from django.db.backends.base.introspection import BaseDatabaseIntrospection
 from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo
-from django.db.backends.base.introspection import TableInfo
+from django.db.backends.base.introspection import TableInfo as BaseTableInfo
 from django.utils.functional import cached_property

-FieldInfo = namedtuple("FieldInfo", BaseFieldInfo._fields + ("is_autofield", "is_json"))
+FieldInfo = namedtuple(
+    "FieldInfo", BaseFieldInfo._fields + ("is_autofield", "is_json", "comment")
+)
+TableInfo = namedtuple("TableInfo", BaseTableInfo._fields + ("comment",))


 class DatabaseIntrospection(BaseDatabaseIntrospection):
@@ -77,8 +80,14 @@ def get_table_list(self, cursor):
         """Return a list of table and view names in the current database."""
         cursor.execute(
             """
-            SELECT table_name, 't'
+            SELECT
+                user_tables.table_name,
+                't',
+                user_tab_comments.comments
             FROM user_tables
+            LEFT OUTER JOIN
+                user_tab_comments
+                ON user_tab_comments.table_name = user_tables.table_name
             WHERE
                 NOT EXISTS (
                     SELECT 1
@@ -86,13 +95,13 @@ def get_table_list(self, cursor):
                     WHERE user_mviews.mview_name = user_tables.table_name
                 )
             UNION ALL
-            SELECT view_name, 'v' FROM user_views
+            SELECT view_name, 'v', NULL FROM user_views
             UNION ALL
-            SELECT mview_name, 'v' FROM user_mviews
+            SELECT mview_name, 'v', NULL FROM user_mviews
         """
         )
         return [
-            TableInfo(self.identifier_converter(row[0]), row[1])
+            TableInfo(self.identifier_converter(row[0]), row[1], row[2])
             for row in cursor.fetchall()
         ]

@@ -131,10 +140,15 @@ def get_table_description(self, cursor, table_name):
                     )
                     THEN 1
                     ELSE 0
-                END as is_json
+                END as is_json,
+                user_col_comments.comments as col_comment
             FROM user_tab_cols
             LEFT OUTER JOIN
                 user_tables ON user_tables.table_name = user_tab_cols.table_name
+            LEFT OUTER JOIN
+                user_col_comments ON
+                user_col_comments.column_name = user_tab_cols.column_name AND
+                user_col_comments.table_name = user_tab_cols.table_name
             WHERE user_tab_cols.table_name = UPPER(%s)
             """,
             [table_name],
@@ -146,6 +160,7 @@ def get_table_description(self, cursor, table_name):
                 collation,
                 is_autofield,
                 is_json,
+                comment,
             )
             for (
                 column,
@@ -154,6 +169,7 @@ def get_table_description(self, cursor, table_name):
                 display_size,
                 is_autofield,
                 is_json,
+                comment,
             ) in cursor.fetchall()
         }
         self.cache_bust_counter += 1
@@ -165,7 +181,14 @@ def get_table_description(self, cursor, table_name):
         description = []
         for desc in cursor.description:
             name = desc[0]
-            display_size, default, collation, is_autofield, is_json = field_map[name]
+            (
+                display_size,
+                default,
+                collation,
+                is_autofield,
+                is_json,
+                comment,
+            ) = field_map[name]
             name %= {}  # cx_Oracle, for some reason, doubles percent signs.
             description.append(
                 FieldInfo(
@@ -180,6 +203,7 @@ def get_table_description(self, cursor, table_name):
                     collation,
                     is_autofield,
                     is_json,
+                    comment,
                 )
             )
         return description
diff --git a/django/db/backends/postgresql/features.py b/django/db/backends/postgresql/features.py
--- a/django/db/backends/postgresql/features.py
+++ b/django/db/backends/postgresql/features.py
@@ -22,6 +22,7 @@ class DatabaseFeatures(BaseDatabaseFeatures):
     has_select_for_update_skip_locked = True
     has_select_for_no_key_update = True
     can_release_savepoints = True
+    supports_comments = True
     supports_tablespaces = True
     supports_transactions = True
     can_introspect_materialized_views = True
diff --git a/django/db/backends/postgresql/introspection.py b/django/db/backends/postgresql/introspection.py
--- a/django/db/backends/postgresql/introspection.py
+++ b/django/db/backends/postgresql/introspection.py
@@ -2,10 +2,11 @@

 from django.db.backends.base.introspection import BaseDatabaseIntrospection
 from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo
-from django.db.backends.base.introspection import TableInfo
+from django.db.backends.base.introspection import TableInfo as BaseTableInfo
 from django.db.models import Index

-FieldInfo = namedtuple("FieldInfo", BaseFieldInfo._fields + ("is_autofield",))
+FieldInfo = namedtuple("FieldInfo", BaseFieldInfo._fields + ("is_autofield", "comment"))
+TableInfo = namedtuple("TableInfo", BaseTableInfo._fields + ("comment",))


 class DatabaseIntrospection(BaseDatabaseIntrospection):
@@ -62,7 +63,8 @@ def get_table_list(self, cursor):
                     WHEN c.relispartition THEN 'p'
                     WHEN c.relkind IN ('m', 'v') THEN 'v'
                     ELSE 't'
-                END
+                END,
+                obj_description(c.oid)
             FROM pg_catalog.pg_class c
             LEFT JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace
             WHERE c.relkind IN ('f', 'm', 'p', 'r', 'v')
@@ -91,7 +93,8 @@ def get_table_description(self, cursor, table_name):
                 NOT (a.attnotnull OR (t.typtype = 'd' AND t.typnotnull)) AS is_nullable,
                 pg_get_expr(ad.adbin, ad.adrelid) AS column_default,
                 CASE WHEN collname = 'default' THEN NULL ELSE collname END AS collation,
-                a.attidentity != '' AS is_autofield
+                a.attidentity != '' AS is_autofield,
+                col_description(a.attrelid, a.attnum) AS column_comment
             FROM pg_attribute a
             LEFT JOIN pg_attrdef ad ON a.attrelid = ad.adrelid AND a.attnum = ad.adnum
             LEFT JOIN pg_collation co ON a.attcollation = co.oid
diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py
--- a/django/db/migrations/autodetector.py
+++ b/django/db/migrations/autodetector.py
@@ -170,6 +170,7 @@ def _detect_changes(self, convert_apps=None, graph=None):
         self.generate_created_proxies()
         self.generate_altered_options()
         self.generate_altered_managers()
+        self.generate_altered_db_table_comment()

         # Create the renamed fields and store them in self.renamed_fields.
         # They are used by create_altered_indexes(), generate_altered_fields(),
@@ -1552,6 +1553,28 @@ def generate_altered_db_table(self):
                     ),
                 )

+    def generate_altered_db_table_comment(self):
+        models_to_check = self.kept_model_keys.union(
+            self.kept_proxy_keys, self.kept_unmanaged_keys
+        )
+        for app_label, model_name in sorted(models_to_check):
+            old_model_name = self.renamed_models.get(
+                (app_label, model_name), model_name
+            )
+            old_model_state = self.from_state.models[app_label, old_model_name]
+            new_model_state = self.to_state.models[app_label, model_name]
+
+            old_db_table_comment = old_model_state.options.get("db_table_comment")
+            new_db_table_comment = new_model_state.options.get("db_table_comment")
+            if old_db_table_comment != new_db_table_comment:
+                self.add_operation(
+                    app_label,
+                    operations.AlterModelTableComment(
+                        name=model_name,
+                        table_comment=new_db_table_comment,
+                    ),
+                )
+
     def generate_altered_options(self):
         """
         Work out if any non-schema-affecting options have changed and make an
diff --git a/django/db/migrations/operations/__init__.py b/django/db/migrations/operations/__init__.py
--- a/django/db/migrations/operations/__init__.py
+++ b/django/db/migrations/operations/__init__.py
@@ -6,6 +6,7 @@
     AlterModelManagers,
     AlterModelOptions,
     AlterModelTable,
+    AlterModelTableComment,
     AlterOrderWithRespectTo,
     AlterUniqueTogether,
     CreateModel,
@@ -21,6 +22,7 @@
     "CreateModel",
     "DeleteModel",
     "AlterModelTable",
+    "AlterModelTableComment",
     "AlterUniqueTogether",
     "RenameModel",
     "AlterIndexTogether",
diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py
--- a/django/db/migrations/operations/models.py
+++ b/django/db/migrations/operations/models.py
@@ -529,6 +529,44 @@ def migration_name_fragment(self):
         return "alter_%s_table" % self.name_lower


+class AlterModelTableComment(ModelOptionOperation):
+    def __init__(self, name, table_comment):
+        self.table_comment = table_comment
+        super().__init__(name)
+
+    def deconstruct(self):
+        kwargs = {
+            "name": self.name,
+            "table_comment": self.table_comment,
+        }
+        return (self.__class__.__qualname__, [], kwargs)
+
+    def state_forwards(self, app_label, state):
+        state.alter_model_options(
+            app_label, self.name_lower, {"db_table_comment": self.table_comment}
+        )
+
+    def database_forwards(self, app_label, schema_editor, from_state, to_state):
+        new_model = to_state.apps.get_model(app_label, self.name)
+        if self.allow_migrate_model(schema_editor.connection.alias, new_model):
+            old_model = from_state.apps.get_model(app_label, self.name)
+            schema_editor.alter_db_table_comment(
+                new_model,
+                old_model._meta.db_table_comment,
+                new_model._meta.db_table_comment,
+            )
+
+    def database_backwards(self, app_label, schema_editor, from_state, to_state):
+        return self.database_forwards(app_label, schema_editor, from_state, to_state)
+
+    def describe(self):
+        return f"Alter {self.name} table comment"
+
+    @property
+    def migration_name_fragment(self):
+        return f"alter_{self.name_lower}_table_comment"
+
+
 class AlterTogetherOptionOperation(ModelOptionOperation):
     option_name = None

diff --git a/django/db/models/base.py b/django/db/models/base.py
--- a/django/db/models/base.py
+++ b/django/db/models/base.py
@@ -1556,6 +1556,7 @@ def check(cls, **kwargs):
                 *cls._check_ordering(),
                 *cls._check_constraints(databases),
                 *cls._check_default_pk(),
+                *cls._check_db_table_comment(databases),
             ]

         return errors
@@ -1592,6 +1593,29 @@ def _check_default_pk(cls):
             ]
         return []

+    @classmethod
+    def _check_db_table_comment(cls, databases):
+        if not cls._meta.db_table_comment:
+            return []
+        errors = []
+        for db in databases:
+            if not router.allow_migrate_model(db, cls):
+                continue
+            connection = connections[db]
+            if not (
+                connection.features.supports_comments
+                or "supports_comments" in cls._meta.required_db_features
+            ):
+                errors.append(
+                    checks.Warning(
+                        f"{connection.display_name} does not support comments on "
+                        f"tables (db_table_comment).",
+                        obj=cls,
+                        id="models.W046",
+                    )
+                )
+        return errors
+
     @classmethod
     def _check_swappable(cls):
         """Check if the swapped model exists."""
diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py
--- a/django/db/models/fields/__init__.py
+++ b/django/db/models/fields/__init__.py
@@ -200,6 +200,7 @@ def __init__(
         auto_created=False,
         validators=(),
         error_messages=None,
+        db_comment=None,
     ):
         self.name = name
         self.verbose_name = verbose_name  # May be set by set_attributes_from_name
@@ -221,6 +222,7 @@ def __init__(
         self.help_text = help_text
         self.db_index = db_index
         self.db_column = db_column
+        self.db_comment = db_comment
         self._db_tablespace = db_tablespace
         self.auto_created = auto_created

@@ -259,6 +261,7 @@ def check(self, **kwargs):
             *self._check_field_name(),
             *self._check_choices(),
             *self._check_db_index(),
+            *self._check_db_comment(**kwargs),
             *self._check_null_allowed_for_primary_keys(),
             *self._check_backend_specific_checks(**kwargs),
             *self._check_validators(),
@@ -385,6 +388,28 @@ def _check_db_index(self):
         else:
             return []

+    def _check_db_comment(self, databases=None, **kwargs):
+        if not self.db_comment or not databases:
+            return []
+        errors = []
+        for db in databases:
+            if not router.allow_migrate_model(db, self.model):
+                continue
+            connection = connections[db]
+            if not (
+                connection.features.supports_comments
+                or "supports_comments" in self.model._meta.required_db_features
+            ):
+                errors.append(
+                    checks.Warning(
+                        f"{connection.display_name} does not support comments on "
+                        f"columns (db_comment).",
+                        obj=self,
+                        id="fields.W163",
+                    )
+                )
+        return errors
+
     def _check_null_allowed_for_primary_keys(self):
         if (
             self.primary_key
@@ -538,6 +563,7 @@ def deconstruct(self):
             "choices": None,
             "help_text": "",
             "db_column": None,
+            "db_comment": None,
             "db_tablespace": None,
             "auto_created": False,
             "validators": [],
diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py
--- a/django/db/models/fields/related.py
+++ b/django/db/models/fields/related.py
@@ -1428,6 +1428,14 @@ def _check_ignored_options(self, **kwargs):
                     id="fields.W345",
                 )
             )
+        if self.db_comment:
+            warnings.append(
+                checks.Warning(
+                    "db_comment has no effect on ManyToManyField.",
+                    obj=self,
+                    id="fields.W346",
+                )
+            )

         return warnings

diff --git a/django/db/models/options.py b/django/db/models/options.py
--- a/django/db/models/options.py
+++ b/django/db/models/options.py
@@ -30,6 +30,7 @@
     "verbose_name",
     "verbose_name_plural",
     "db_table",
+    "db_table_comment",
     "ordering",
     "unique_together",
     "permissions",
@@ -112,6 +113,7 @@ def __init__(self, meta, app_label=None):
         self.verbose_name = None
         self.verbose_name_plural = None
         self.db_table = ""
+        self.db_table_comment = ""
         self.ordering = []
         self._ordering_clash = False
         self.indexes = []

</patch>

--------------------------------------------------
analyze
There are common problems in this case. From the reference code, we can see that in the end to implement the functions in propt, a large number of files need to be modified. All three models only consider some of the content.
text:
<issue>
Better Indication of Squash Migration State in showmigrations
Description

In the discussion of #25231 (​https://github.com/django/django/pull/5112) it became clear that there was a disconnect between the current output of showmigrations and the actual recorded applied state of squashed migrations.
Currently if all of the replaced/original migrations have been run, showmigrations will output that the related squashed migration has been applied with an [X] in the output even if that has not yet been recorded by the migration recorder. However, it is currently a requirement that migrate be run to record this applied state for the squashed migration before the original migrations are removed. If a deployment process is looking for an empty [ ] to know to run the migration then this may trip it up.
This case is to consider an output for showmigrations which can indicate that this migration has only been "soft" applied, that is applied but not recorded yet.
Changes to the planner for such an output may also impact #24900.

</issue>

steps:
1. Modify the `show_list` method in `django/core/management/commands/showmigrations.py` to indicate "softly applied" squashed migrations. Iterate through each migration in `show_list`.
2. Inside the loop, after determining if `applied_migration` exists and if the migration is a squashed one, add a condition to check for "softly applied" state.
3. The "softly applied" condition is met when a migration is a squashed migration, it is not in `loader.applied_migrations`, but all migrations it replaces are in `loader.applied_migrations`.
4. If the "softly applied" condition is true, set `output` to `' [S] %s'` and write to `self.stdout`.
5. If `applied_migration` is true, the output remains `' [X] %s'`.
6. If neither of the above conditions are met (not applied and not softly applied), the output remains `" [ ] %s"`.
7. Modify the `show_plan` method in `django/core/management/commands/showmigrations.py` to indicate "softly applied" squashed migrations. Iterate through each node in `show_plan`.
8. Inside the loop, check if the current `node` corresponds to a squashed migration by checking `node.migration.replaces`.
9. Check if the `node.key` is in `loader.applied_migrations`.
10. If the migration is squashed and `node.key` is not in `loader.applied_migrations`, check if all migrations in `node.migration.replaces` are in `loader.applied_migrations`.
11. If all replaced migrations are applied, output `[S]  %s.%s%s`.
12. If `node.key` is in `loader.applied_migrations`, output `[X]  %s.%s%s`.
13. Otherwise, output `[ ]  %s.%s%s`.
14. Generate the patch file using `git diff` command.
model_patch:

--- a/django/core/management/commands/showmigrations.py
+++ b/django/core/management/commands/showmigrations.py
@@ -91,7 +91,17 @@
                         title = plan_node[1]
                         if graph.nodes[plan_node].replaces:
                             title += " (%s squashed migrations)" % len(graph.nodes[plan_node].replaces)
+                        migration_node = graph.nodes[plan_node]
                         applied_migration = loader.applied_migrations.get(plan_node)
+                        soft_applied = False
+                        if migration_node.replaces and not applied_migration:
+                            soft_applied = True
+                            for replaced_migration_name in migration_node.replaces:
+                                if replaced_migration_name not in loader.applied_migrations:
+                                    soft_applied = False
+                                    break
+                        if soft_applied:
+                            output = ' [S] %s' % title
                         # Mark it as applied/unapplied
                         if applied_migration:
                             output = ' [X] %s' % title
@@ -142,7 +152,18 @@
             deps = ""
             if self.verbosity >= 2:
                 deps = print_deps(node)
-             if node.key in loader.applied_migrations:
+            soft_applied = False
+            if node.migration.replaces and node.key not in loader.applied_migrations:
+                soft_applied = True
+                for replaced_migration_name in node.migration.replaces:
+                    if replaced_migration_name not in loader.applied_migrations:
+                        soft_applied = False
+                        break
+
+            if soft_applied:
+                self.stdout.write("[S]  %s.%s%s" % (node.key[0], node.key[1], deps))
+            elif node.key in loader.applied_migrations:
+
                 self.stdout.write("[X]  %s.%s%s" % (node.key[0], node.key[1], deps))
             else:
                 self.stdout.write("[ ]  %s.%s%s" % (node.key[0], node.key[1], deps))


gold_patch:
<patch>
diff --git a/django/core/management/commands/showmigrations.py b/django/core/management/commands/showmigrations.py
--- a/django/core/management/commands/showmigrations.py
+++ b/django/core/management/commands/showmigrations.py
@@ -4,6 +4,7 @@
 from django.core.management.base import BaseCommand
 from django.db import DEFAULT_DB_ALIAS, connections
 from django.db.migrations.loader import MigrationLoader
+from django.db.migrations.recorder import MigrationRecorder


 class Command(BaseCommand):
@@ -69,6 +70,8 @@ def show_list(self, connection, app_names=None):
         """
         # Load migrations from disk/DB
         loader = MigrationLoader(connection, ignore_no_migrations=True)
+        recorder = MigrationRecorder(connection)
+        recorded_migrations = recorder.applied_migrations()
         graph = loader.graph
         # If we were passed a list of apps, validate it
         if app_names:
@@ -91,7 +94,11 @@ def show_list(self, connection, app_names=None):
                         applied_migration = loader.applied_migrations.get(plan_node)
                         # Mark it as applied/unapplied
                         if applied_migration:
-                            output = ' [X] %s' % title
+                            if plan_node in recorded_migrations:
+                                output = ' [X] %s' % title
+                            else:
+                                title += " Run 'manage.py migrate' to finish recording."
+                                output = ' [-] %s' % title
                             if self.verbosity >= 2 and hasattr(applied_migration, 'applied'):
                                 output += ' (applied at %s)' % applied_migration.applied.strftime('%Y-%m-%d %H:%M:%S')
                             self.stdout.write(output)

</patch>

--------------------------------------------------
analyze
text:
<issue>
django.db.backends logging output should include the database alias
Description

		(last modified by David Winterbottom)

As this is essential information when working with database routing.
PR: ​https://github.com/django/django/pull/11994

</issue>

steps:

1. Open the file `django/db/backends/base/base.py`.
2. Locate the `CursorDebugWrapper` class.
3. Inside the `CursorDebugWrapper` class, find the `execute` method.
4. Modify the logging statement in the `execute` method to include the database alias `self.db.alias`.  Prepend the alias in square brackets to the log message. For example, change `logger.debug(...)` to `logger.debug(f"[{self.db.alias}] ...")`.
5. Locate the `executemany` method in the `CursorDebugWrapper` class.
6. Modify the logging statement in the `executemany` method to include the database alias `self.db.alias` in the same way as in step 4.
7. Save the changes to `django/db/backends/base/base.py`.
8. Generate a patch file using `git diff` for the modified file `django/db/backends/base/base.py`.

model_patch:

--- a/django/db/backends/base/base.py
+++ b/django/db/backends/base/base.py
@@ -7,6 +7,7 @@
 from collections import deque
 from contextlib import contextmanager

+import logging
 import pytz

 from django.conf import settings
@@ -19,6 +20,8 @@
 from django.utils import timezone
 from django.utils.asyncio import async_unsafe
 from django.utils.functional import cached_property
+
+logger = logging.getLogger('django.db.backends')

 23 NO_DB_ALIAS = '__no_db__'

@@ -586,6 +589,24 @@
     def make_debug_cursor(self, cursor):
         """Create a cursor that logs all queries in self.queries_log."""
         return utils.CursorDebugWrapper(cursor, self)
+
+
+class CursorDebugWrapper(utils.CursorWrapper):
+
+    def execute(self, sql, params=None):
+        start = time.monotonic()
+        try:
+            return self.cursor.execute(sql, params)
+        finally:
+            duration = time.monotonic() - start
+            raw_sql = self.db.ops.last_executed_query(self.cursor, sql, params)
+            # logger.debug() won't log properly until logging.basicConfig() is called.
+            # In��eneral DEBUG=True is set in settings.py which does call it, but there
+            # are cases such as in test setup where settings.py is not read, but debugging
+            # is still helpful.
+            if logger.handlers:
+                logger.debug(
+                    '[%s] %s', self.db.alias, self.db.display_name, {'duration': duration, 'sql': raw_sql, 'params': params})

      def make_cursor(self, cursor):
         """Create a cursor without debug logging."""


gold_patch:
<patch>
diff --git a/django/db/backends/utils.py b/django/db/backends/utils.py
--- a/django/db/backends/utils.py
+++ b/django/db/backends/utils.py
@@ -121,11 +121,12 @@ def debug_sql(self, sql=None, params=None, use_last_executed_query=False, many=F
                 'time': '%.3f' % duration,
             })
             logger.debug(
-                '(%.3f) %s; args=%s',
+                '(%.3f) %s; args=%s; alias=%s',
                 duration,
                 sql,
                 params,
-                extra={'duration': duration, 'sql': sql, 'params': params},
+                self.db.alias,
+                extra={'duration': duration, 'sql': sql, 'params': params, 'alias': self.db.alias},
             )



</patch>

--------------------------------------------------
analyze

text:
<issue>
Allow delete to provide a success message through a mixin.
Description

Add a mixin to show a message on successful object deletion.

</issue>

steps:

1. Open the file `django/contrib/messages/views.py`.
2. Create a new mixin class named `SuccessMessageDeleteMixin` after the `SuccessMessageMixin` class.
3. Add a `success_message` attribute to `SuccessMessageDeleteMixin` and set it to an empty string as default.
4. Define a `delete` method in `SuccessMessageDeleteMixin` that takes `request`, `*args`, and `**kwargs` as arguments.
5. Inside the `delete` method, call `super().delete(request, *args, **kwargs)` to execute the original delete logic from the parent class (likely `DeletionMixin`). Store the returned `HttpResponseRedirect` in a variable named `response`.
6. After calling `super().delete()`, call a new method `self.get_success_message(self.object)` to get the success message string. Store the result in a variable named `success_message`.
7. Check if `success_message` is not empty (truthy).
8. If `success_message` is not empty, use `from django.contrib import messages` and then call `messages.success(self.request, success_message)`.
9. Return the `response` variable to ensure the redirect happens as intended.
10. Define the `get_success_message` method in `SuccessMessageDeleteMixin` that takes `obj` as an argument.
11. In `get_success_message`, return `self.success_message % obj.__dict__` to allow formatting the message string using the object's attributes.
12. Open the file `django/views/generic/edit.py`.
13. Import `SuccessMessageDeleteMixin` from `django.contrib.messages.views`.
14. Modify the `DeleteView` class to inherit from `SuccessMessageDeleteMixin` before `SingleObjectTemplateResponseMixin` and `BaseDeleteView`. The order is important to ensure `SuccessMessageDeleteMixin`'s `delete` method is called.
15. Save both files.
16. Create a patch file encompassing these changes.

model_patch:

--- a/django/contrib/messages/views.py
+++ b/django/contrib/messages/views.py
@@ -19,3 +19,20 @@
      def get_success_message(self, cleaned_data):
          return self.success_message % cleaned_data

+
+class SuccessMessageDeleteMixin:
+    """
+    Add a success message on successful object deletion.
+    """
+    success_message = ''
+
+    def delete(self, request, *args, **kwargs):
+        response = super().delete(request, *args, **kwargs)
+        success_message = self.get_success_message(self.object)
+        if success_message:
+            messages.success(self.request, success_message)
+        return response
+
+    def get_success_message(self, obj):
+        return self.success_message % obj.__dict__
+
--- a/django/views/generic/edit.py
+++ b/django/views/generic/edit.py
@@ -1,6 +1,7 @@
 from django.core.exceptions import ImproperlyConfigured
 from django.forms import models as model_forms
 from django.http import HttpResponseRedirect
+from django.contrib.messages.views import SuccessMessageDeleteMixin
 from django.views.generic.base import ContextMixin, TemplateResponseMixin, View
 from django.views.generic.detail import (
     BaseDetailView, SingleObjectMixin, SingleObjectTemplateResponseMixin,
@@ -236,7 +237,7 @@
  class DeleteView(SingleObjectTemplateResponseMixin, BaseDeleteView):
      """
      View for deleting an object retrieved with self.get_object(), with a
-     response rendered by a template.
+     response rendered by a template."""
      template_name_suffix = '_confirm_delete'


gold_patch:
<patch>
diff --git a/django/views/generic/edit.py b/django/views/generic/edit.py
--- a/django/views/generic/edit.py
+++ b/django/views/generic/edit.py
@@ -1,5 +1,5 @@
 from django.core.exceptions import ImproperlyConfigured
-from django.forms import models as model_forms
+from django.forms import Form, models as model_forms
 from django.http import HttpResponseRedirect
 from django.views.generic.base import ContextMixin, TemplateResponseMixin, View
 from django.views.generic.detail import (
@@ -225,12 +225,30 @@ def get_success_url(self):
                 "No URL to redirect to. Provide a success_url.")


-class BaseDeleteView(DeletionMixin, BaseDetailView):
+class BaseDeleteView(DeletionMixin, FormMixin, BaseDetailView):
     """
     Base view for deleting an object.

     Using this base class requires subclassing to provide a response mixin.
     """
+    form_class = Form
+
+    def post(self, request, *args, **kwargs):
+        # Set self.object before the usual form processing flow.
+        # Inlined because having DeletionMixin as the first base, for
+        # get_success_url(), makes leveraging super() with ProcessFormView
+        # overly complex.
+        self.object = self.get_object()
+        form = self.get_form()
+        if form.is_valid():
+            return self.form_valid(form)
+        else:
+            return self.form_invalid(form)
+
+    def form_valid(self, form):
+        success_url = self.get_success_url()
+        self.object.delete()
+        return HttpResponseRedirect(success_url)


 class DeleteView(SingleObjectTemplateResponseMixin, BaseDeleteView):

</patch>

--------------------------------------------------
analyze
The solution proposed by Gemini is almost the same as deepseek, except that the naming is slightly different, but what Gemini is better is that it understands that the newly added Mixin will be introduced into edit.py.

text:
<issue>
Make makemigrations scriptable / script-friendly
Description

Currently, the makemigrations management command doesn't lend itself well to scripting. For example, it writes its progress output to stdout rather than stderr. Also, there doesn't appear to be a structured / programmatic way to figure out what files it has created.
My use case is that in my development environment, I'd like to be able to run makemigrations in a Docker container, find out what files were added (e.g. from makemigrations's output), and then copy those files from the Docker container to my development machine so they can be added to source control.
Currently, there doesn't seem to be an easy way to do this. One way, for example, is to manually read makemigrations's output to find out what apps were affected, and then inspect the directories yourself for the new files.
Better, for example, would be if makemigrations could write the paths to the created files to stdout.

</issue>

steps:

1. Modify the `log` method in `django/core/management/commands/makemigrations.py` to write to `stderr` instead of `stdout`. This will redirect general progress messages to stderr.
2. Modify the `write_migration_files` method in `django/core/management/commands/makemigrations.py` to collect the paths of created migration files. Initialize an empty list `created_files`.
3. Inside the loop in `write_migration_files`, when a migration file path `writer.path` is determined and written (or would be written in dry-run), append `migration_string` (which is the relative or absolute path) to the `created_files` list. This should happen both in normal and dry-run modes if verbosity is sufficient to show the output.
4. After the loops in `write_migration_files`, return the `created_files` list.
5. Modify the `handle` method in `django/core/management/commands/makemigrations.py`. After calling `self.write_migration_files(changes)`, retrieve the returned `created_files` list.
6. In the `handle` method, iterate through the `created_files` list. If the list is not empty, write each file path to `self.stdout` using `self.stdout.write()`, so that they are printed to standard output, one file per line. Add a header message before printing the file list to make the output clearer.
7. Generate a patch file containing the changes made to `django/core/management/commands/makemigrations.py`.

model_patch:

--- a/django/core/management/commands/makemigrations.py
+++ b/django/core/management/commands/makemigrations.py
@@ -61,7 +61,7 @@
         )

      def log(self, msg):
-         self.stdout.write(msg)
+         self.stderr.write(msg)

      @no_translations
      def handle(self, *app_labels, **options):
@@ -202,6 +202,7 @@
                  else:
                      self.log('No changes detected')
          else:
+             msg = self.write_migration_files(changes)
              self.write_migration_files(changes)
              if check_changes:
                  sys.exit(1)
@@ -209,10 +210,12 @@
      def write_migration_files(self, changes):
          """
          Take a changes dict and write them out as migration files.
+         Return a list of paths to created migration files.
         """
          directory_created = {}
+         created_files = []
          for app_label, app_migrations in changes.items():
-             if self.verbosity >= 1:
+             if self.verbosity >= 2:
                  self.log(self.style.MIGRATE_HEADING("Migrations for '%s':" % app_label))
              for migration in app_migrations:
                  # Describe the migration
@@ -226,7 +229,7 @@
                          migration_string = writer.path
                      if migration_string.startswith('..'):
                          migration_string = writer.path
-                     self.log('  %s\n' % self.style.MIGRATE_LABEL(migration_string))
+                     self.log('  %s' % self.style.MIGRATE_LABEL(migration_string))
                      for operation in migration.operations:
                          self.log('    - %s' % operation.describe())
                  if not self.dry_run:
@@ -242,6 +245,7 @@
                          directory_created[app_label] = True
                      migration_string = writer.as_string()
                      with open(writer.path, "w", encoding='utf-8') as fh:
+                         created_files.append(migration_string)
                          fh.write(migration_string)
                  elif self.verbosity == 3:
                      # Alternatively, makemigrations --dry-run --verbosity 3
@@ -251,6 +255,15 @@
                          "Full migrations file '%s':" % writer.filename
                      ))
                      self.log(writer.as_string())
+                     created_files.append(writer.path)
+        if created_files and self.verbosity >= 1 and not self.dry_run:
+            output_message = "\nThe following migration files were created:\n"
+            output_message += "\n".join(created_files)
+            self.stdout.write(output_message)
+        elif created_files and self.verbosity >= 1 and self.dry_run:
+             output_message = "\nThe following migration files would have been created (dry-run):\n"
+             output_message += "\n".join(created_files)
+             self.stdout.write(output_message)
+        return created_files

      def handle_merge(self, loader, conflicts):
          """


gold_patch:
<patch>
diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py
--- a/django/core/management/commands/makemigrations.py
+++ b/django/core/management/commands/makemigrations.py
@@ -57,9 +57,20 @@ def add_arguments(self, parser):
             '--check', action='store_true', dest='check_changes',
             help='Exit with a non-zero status if model changes are missing migrations.',
         )
+        parser.add_argument(
+            '--scriptable', action='store_true', dest='scriptable',
+            help=(
+                'Divert log output and input prompts to stderr, writing only '
+                'paths of generated migration files to stdout.'
+            ),
+        )
+
+    @property
+    def log_output(self):
+        return self.stderr if self.scriptable else self.stdout

     def log(self, msg):
-        self.stdout.write(msg)
+        self.log_output.write(msg)

     @no_translations
     def handle(self, *app_labels, **options):
@@ -73,6 +84,10 @@ def handle(self, *app_labels, **options):
             raise CommandError('The migration name must be a valid Python identifier.')
         self.include_header = options['include_header']
         check_changes = options['check_changes']
+        self.scriptable = options['scriptable']
+        # If logs and prompts are diverted to stderr, remove the ERROR style.
+        if self.scriptable:
+            self.stderr.style_func = None

         # Make sure the app they asked for exists
         app_labels = set(app_labels)
@@ -147,7 +162,7 @@ def handle(self, *app_labels, **options):
             questioner = InteractiveMigrationQuestioner(
                 specified_apps=app_labels,
                 dry_run=self.dry_run,
-                prompt_output=self.stdout,
+                prompt_output=self.log_output,
             )
         else:
             questioner = NonInteractiveMigrationQuestioner(
@@ -226,6 +241,8 @@ def write_migration_files(self, changes):
                     self.log('  %s\n' % self.style.MIGRATE_LABEL(migration_string))
                     for operation in migration.operations:
                         self.log('    - %s' % operation.describe())
+                    if self.scriptable:
+                        self.stdout.write(migration_string)
                 if not self.dry_run:
                     # Write the migrations file to the disk.
                     migrations_directory = os.path.dirname(writer.path)
@@ -254,7 +271,7 @@ def handle_merge(self, loader, conflicts):
         if it's safe; otherwise, advises on how to fix it.
         """
         if self.interactive:
-            questioner = InteractiveMigrationQuestioner(prompt_output=self.stdout)
+            questioner = InteractiveMigrationQuestioner(prompt_output=self.log_output)
         else:
             questioner = MigrationQuestioner(defaults={'ask_merge': True})

@@ -327,6 +344,8 @@ def all_items_equal(seq):
                         fh.write(writer.as_string())
                     if self.verbosity > 0:
                         self.log('\nCreated new merge migration %s' % writer.path)
+                        if self.scriptable:
+                            self.stdout.write(writer.path)
                 elif self.verbosity == 3:
                     # Alternatively, makemigrations --merge --dry-run --verbosity 3
                     # will log the merge migrations rather than saving the file

</patch>

--------------------------------------------------
analyze
The method I think about here is basically correct. The hint word description may be a bit unclear, which is different from the new option added to the standard answer. The solution choice given by Gemini overrides the log method instead of adding log_output. It seems that the docker error is reported when looking at the run result log.
text:
<issue>
Refactor AutocompleteJsonView to support extra fields in autocomplete response

Refactoring AutocompleteJsonView to support additional fields in automatic completion responses

Description

		(last modified by mrts)

Adding data attributes to items in ordinary non-autocomplete foreign key fields that use forms.widgets.Select-based widgets is relatively easy. This enables powerful and dynamic admin site customizations where fields from related models are updated immediately when users change the selected item】
However, adding new attributes to autocomplete field results currently requires extending contrib.admin.views.autocomplete.AutocompleteJsonView and fully overriding the AutocompleteJsonView.get() method. Here's an example:
class MyModelAdmin(admin.ModelAdmin):
	def get_urls(self):
		return [
			path('autocomplete/', CustomAutocompleteJsonView.as_view(admin_site=self.admin_site))
			if url.pattern.match('autocomplete/')
			else url for url in super().get_urls()
		]
class CustomAutocompleteJsonView(AutocompleteJsonView):
	def get(self, request, *args, **kwargs):
		self.term, self.model_admin, self.source_field, to_field_name = self.process_request(request)
		if not self.has_perm(request):
			raise PermissionDenied
		self.object_list = self.get_queryset()
		context = self.get_context_data()
		return JsonResponse({
			'results': [
				{'id': str(getattr(obj, to_field_name)), 'text': str(obj), 'notes': obj.notes} # <-- customization here
				for obj in context['object_list']
			],
			'pagination': {'more': context['page_obj'].has_next()},
		})
The problem with this is that as AutocompleteJsonView.get() keeps evolving, there's quite a lot of maintenance overhead required to catch up.
The solutions is simple, side-effect- and risk-free: adding a result customization extension point to get() by moving the lines that construct the results inside JsonResponse constructor to a separate method. So instead of
		return JsonResponse({
			'results': [
				{'id': str(getattr(obj, to_field_name)), 'text': str(obj)}
				for obj in context['object_list']
			],
			'pagination': {'more': context['page_obj'].has_next()},
		})
there would be
		return JsonResponse({
			'results': [
				self.serialize_result(obj, to_field_name) for obj in context['object_list']
			],
			'pagination': {'more': context['page_obj'].has_next()},
		})
where serialize_result() contains the original object to dictionary conversion code that would be now easy to override:
def serialize_result(self, obj, to_field_name):
	return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}
The example CustomAutocompleteJsonView from above would now become succinct and maintainable:
class CustomAutocompleteJsonView(AutocompleteJsonView):
	def serialize_result(self, obj, to_field_name):
		return super.serialize_result(obj, to_field_name) | {'notes': obj.notes}
What do you think, is this acceptable? I'm more than happy to provide the patch.

</issue>

steps:

1. Open the file `django/contrib/admin/views/autocomplete.py`.
2. Locate the `get` method in the `AutocompleteJsonView` class.
3. Extract the list comprehension within the `JsonResponse` constructor in the `get` method into a new method called `serialize_result`. This method should take `obj` and `to_field_name` as arguments and return a dictionary `{'id': ..., 'text': ...}`.
4. Replace the original list comprehension in the `get` method with a call to the new `serialize_result` method within a list comprehension.
5. Save the changes to `django/contrib/admin/views/autocomplete.py`.
6. Generate a patch file using `git diff` or a similar tool, comparing the modified file with the original version. Ensure the patch is in the correct format, omitting line numbers and only including the diff content with `+` and `-` prefixes.

model_patch:

--- a/django/contrib/admin/views/autocomplete.py
+++ b/django/contrib/admin/views/autocomplete.py
@@ -25,14 +25,19 @@

         self.object_list = self.get_queryset()
         context = self.get_context_data()
+        return JsonResponse({
+            'results': [
+                self.serialize_result(obj, to_field_name)
+                for obj in context['object_list']
+            ],
+            'pagination': {'more': context['page_obj'].has_next()},
+        })
+
+    def serialize_result(self, obj, to_field_name):
+        """Serialize result to dict."""
         return JsonResponse({
             'results': [
                 {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}
-                for obj in context['object_list']
-            ],
-            'pagination': {'more': context['page_obj'].has_next()},
-        })
-
-    def get_paginator(self, *args, **kwargs):
-        """Use the ModelAdmin's paginator."""
-        return self.model_admin.get_paginator(self.request, *args, **kwargs)
-
-    def get_queryset(self):
-        """Return queryset based on ModelAdmin.get_search_results()."""
-        qs = self.model_admin.get_queryset(self.request)
-        qs = qs.complex_filter(self.source_field.get_limit_choices_to())
-        qs, search_use_distinct = self.model_admin.get_search_results(self.request, qs, self.term)
-        if search_use_distinct:
-            qs = qs.distinct()
-        return qs
-
-    def process_request(self, request):
-        """
-        Validate request integrity, extract and return request parameters.
-
-        Since the subsequent view permission check requires the target model
-        admin, which is determined here, raise PermissionDenied if the
-        requested app, model or field are malformed.
-
-        Raise Http404 if the target model admin is not configured properly with
-        search_fields.
-        """
-        term = request.GET.get('term', '')
-        try:
-            app_label = request.GET['app_label']
-            model_name = request.GET['model_name']
-            field_name = request.GET['field_name']
-        except KeyError as e:
-            raise PermissionDenied from e
-
-        # Retrieve objects from parameters.
-        try:
-            source_model = apps.get_model(app_label, model_name)
-        except LookupError as e:
-            raise PermissionDenied from e
-
-        try:
-            source_field = source_model._meta.get_field(field_name)
-        except FieldDoesNotExist as e:
-            raise PermissionDenied from e
-        try:
-            remote_model = source_field.remote_field.model
-        except AttributeError as e:
-            raise PermissionDenied from e
-        try:
-            model_admin = self.admin_site._registry[remote_model]
-        except KeyError as e:
-            raise PermissionDenied from e
-
-        # Validate suitability of objects.
-        if not model_admin.get_search_fields(request):
-            raise Http404(
-                '%s must have search_fields for the autocomplete_view.' %
-                type(model_admin).__qualname__
-            )
-
-        to_field_name = getattr(source_field.remote_field, 'field_name', remote_model._meta.pk.attname)
-        to_field_name = remote_model._meta.get_field(to_field_name).attname
-        if not model_admin.to_field_allowed(request, to_field_name):
-            raise PermissionDenied
-
-        return term, model_admin, source_field, to_field_name
-
-    def has_perm(self, request, obj=None):
-        """Check if user has permission to access the related model."""
-        return self.model_admin.has_view_permission(request, obj=obj)
+                for obj in context['object_list']
+            ],
+            'pagination': {'more': context['page_obj'].has_next()},
+        })


gold_patch:
<patch>
diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py
--- a/django/contrib/admin/views/autocomplete.py
+++ b/django/contrib/admin/views/autocomplete.py
@@ -11,7 +11,8 @@ class AutocompleteJsonView(BaseListView):

     def get(self, request, *args, **kwargs):
         """
-        Return a JsonResponse with search results of the form:
+        Return a JsonResponse with search results as defined in
+        serialize_result(), by default:
         {
             results: [{id: "123" text: "foo"}],
             pagination: {more: true}
@@ -26,12 +27,19 @@ def get(self, request, *args, **kwargs):
         context = self.get_context_data()
         return JsonResponse({
             'results': [
-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}
+                self.serialize_result(obj, to_field_name)
                 for obj in context['object_list']
             ],
             'pagination': {'more': context['page_obj'].has_next()},
         })

+    def serialize_result(self, obj, to_field_name):
+        """
+        Convert the provided model object to a dictionary that is added to the
+        results list.
+        """
+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}
+
     def get_paginator(self, *args, **kwargs):
         """Use the ModelAdmin's paginator."""
         return self.model_admin.get_paginator(self.request, *args, **kwargs)

</patch>

--------------------------------------------------
analyze
The logical consistency and coherence of steps 1 to 6 describes how to make necessary modifications in AutocompleteJsonView. The description in Step 3 clearly indicates that the content of the list comprehension needs to be extracted and a new method is created serialize_result (CoT internally consistent)

In model_patch, although the construction of JsonResponse has been modified and the list derivation is extracted into the serialize_result method, the implementation is incomplete. The serialize_result method in model_patch is not defined, resulting in the get method not working normally.
The implementation in gold_patch provides a complete definition of serialize_result method and ensures that the structure of the return dictionary is consistent with the original implementation.


