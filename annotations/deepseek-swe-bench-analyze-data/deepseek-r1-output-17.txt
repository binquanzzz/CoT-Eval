Statistical results
django_django-16100
text:
<issue>
Add transaction handling to Changelist list_editable processing.
Description

It seems that changelist_view in Django admin is missing a transaction. Since the view may change data in database, it should be wrapped in a transaction to prevent unexpected states in case of errors.

</issue>

steps:

1. **Identify the POST processing section in changelist_view**: Locate where the form submission is handled in the ModelAdmin's changelist_view method.
2. **Import the transaction module**: Ensure the transaction module from django.db is available.
3. **Wrap formset processing in a transaction**: Use the transaction.atomic() context manager around the code that saves formset data to the database.

model_patch:

--- a/django/contrib/admin/options.py
+++ b/django/contrib/admin/options.py
@@ -22,6 +22,7 @@
 from django.core.exceptions import (
     FieldDoesNotExist, ImproperlyConfigured, PermissionDenied,
 )
+from django.db import transaction
 from django.http import Http404, HttpResponse, HttpResponseRedirect
 from django.template.response import TemplateResponse
 from django.urls import path, reverse
@@ -2251,11 +2252,12 @@
         if formset is None:
             formset = cl.formset = FormSet(request.POST, request.FILES, queryset=cl.get_queryset(request))

-        if formset.is_valid():
+        if formset.is_valid():
             changecount = 0
             addcount = 0
             changelist_formset_changed_data = []
-            # Process the formset
+            # Process the formset within a transaction
+            with transaction.atomic():
             instances = formset.save(commit=False)
             for obj in formset.deleted_objects:
                 if not self.has_delete_permission(request, obj):


gold_patch:
<patch>
diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py
--- a/django/contrib/admin/options.py
+++ b/django/contrib/admin/options.py
@@ -2011,15 +2011,17 @@ def changelist_view(self, request, extra_context=None):
             )
             if formset.is_valid():
                 changecount = 0
-                for form in formset.forms:
-                    if form.has_changed():
-                        obj = self.save_form(request, form, change=True)
-                        self.save_model(request, obj, form, change=True)
-                        self.save_related(request, form, formsets=[], change=True)
-                        change_msg = self.construct_change_message(request, form, None)
-                        self.log_change(request, obj, change_msg)
-                        changecount += 1
-
+                with transaction.atomic(using=router.db_for_write(self.model)):
+                    for form in formset.forms:
+                        if form.has_changed():
+                            obj = self.save_form(request, form, change=True)
+                            self.save_model(request, obj, form, change=True)
+                            self.save_related(request, form, formsets=[], change=True)
+                            change_msg = self.construct_change_message(
+                                request, form, None
+                            )
+                            self.log_change(request, obj, change_msg)
+                            changecount += 1
                 if changecount:
                     msg = ngettext(
                         "%(count)s %(name)s was changed successfully.",

</patch>

--------------------------------------------------
analyze:
Cot steps are inconsistent with code - Incomplete code
with transaction.atomic() only wraps formset.save(commit=False), but does not contain subsequent database operations (such as delete(), save(), save_m2m()). At the same time, transaction.atomic() here does not specify a database, and the Django's primary database is used by default. router.db_for_write(self.model) should be used to specify the write to the database to ensure that the transaction is executed on the correct database.
text:
<issue>
Log when DB transactions are commited and rollbacked.
Description

Background: I was debugging database calls today with the django.db.backends log.
Problem: The BEGIN SQL calls show up in the logs, but there is no way to see when the transaction is commited or if it is rolled back.
As easy solution would be to log commits and rollbacks as well.

</issue>

steps:

1. **Identify the methods responsible for commit and rollback**: In `django/db/backends/base/base.py`, the `_commit` and `_rollback` methods of `BaseDatabaseWrapper` handle the actual commit and rollback operations.

2. **Add logging statements**: Use the `'django.db.backends'` logger to log "COMMIT" and "ROLLBACK" messages at the debug level within these methods to match existing SQL logging.

3. **Ensure correct logger is used**: The logger `'django.db.backends'` is already used by Django for SQL query logging. Adding debug messages here ensures commit/rollback events appear in the same logs.

4. **Modify the methods**: Insert the logging calls before executing `self.connection.commit()` and `self.connection.rollback()` to log when these operations occur.

model_patch:

--- a/django/db/backends/base/base.py
+++ b/django/db/backends/base/base.py
@@ -4,6 +4,7 @@
 import datetime
 import logging
 import threading
+import logging
 import time
 import warnings
 from collections import deque
@@ -301,11 +302,13 @@
     def _commit(self):
         if self.connection is not None:
             with self.wrap_database_errors:
+                logging.getLogger('django.db.backends').debug("COMMIT")
                 return self.connection.commit()

     def _rollback(self):
         if self.connection is not None:
             with self.wrap_database_errors:
+                logging.getLogger('django.db.backends').debug("ROLLBACK")
                 return self.connection.rollback()

     def _close(self):


gold_patch:
<patch>
diff --git a/django/db/backends/base/base.py b/django/db/backends/base/base.py
--- a/django/db/backends/base/base.py
+++ b/django/db/backends/base/base.py
@@ -8,6 +8,8 @@
 from collections import deque
 from contextlib import contextmanager

+from django.db.backends.utils import debug_transaction
+
 try:
     import zoneinfo
 except ImportError:
@@ -307,12 +309,12 @@ def _cursor(self, name=None):

     def _commit(self):
         if self.connection is not None:
-            with self.wrap_database_errors:
+            with debug_transaction(self, "COMMIT"), self.wrap_database_errors:
                 return self.connection.commit()

     def _rollback(self):
         if self.connection is not None:
-            with self.wrap_database_errors:
+            with debug_transaction(self, "ROLLBACK"), self.wrap_database_errors:
                 return self.connection.rollback()

     def _close(self):
@@ -488,9 +490,11 @@ def set_autocommit(

         if start_transaction_under_autocommit:
             self._start_transaction_under_autocommit()
-        else:
+        elif autocommit:
             self._set_autocommit(autocommit)
-
+        else:
+            with debug_transaction(self, "BEGIN"):
+                self._set_autocommit(autocommit)
         self.autocommit = autocommit

         if autocommit and self.run_commit_hooks_on_set_autocommit_on:
diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py
--- a/django/db/backends/oracle/base.py
+++ b/django/db/backends/oracle/base.py
@@ -13,6 +13,7 @@
 from django.core.exceptions import ImproperlyConfigured
 from django.db import IntegrityError
 from django.db.backends.base.base import BaseDatabaseWrapper
+from django.db.backends.utils import debug_transaction
 from django.utils.asyncio import async_unsafe
 from django.utils.encoding import force_bytes, force_str
 from django.utils.functional import cached_property
@@ -306,7 +307,7 @@ def create_cursor(self, name=None):

     def _commit(self):
         if self.connection is not None:
-            with wrap_oracle_errors():
+            with debug_transaction(self, "COMMIT"), wrap_oracle_errors():
                 return self.connection.commit()

     # Oracle doesn't support releasing savepoints. But we fake them when query
diff --git a/django/db/backends/utils.py b/django/db/backends/utils.py
--- a/django/db/backends/utils.py
+++ b/django/db/backends/utils.py
@@ -144,6 +144,35 @@ def debug_sql(
             )


+@contextmanager
+def debug_transaction(connection, sql):
+    start = time.monotonic()
+    try:
+        yield
+    finally:
+        if connection.queries_logged:
+            stop = time.monotonic()
+            duration = stop - start
+            connection.queries_log.append(
+                {
+                    "sql": "%s" % sql,
+                    "time": "%.3f" % duration,
+                }
+            )
+            logger.debug(
+                "(%.3f) %s; args=%s; alias=%s",
+                duration,
+                sql,
+                None,
+                connection.alias,
+                extra={
+                    "duration": duration,
+                    "sql": sql,
+                    "alias": connection.alias,
+                },
+            )
+
+
 def split_tzname_delta(tzname):
     """
     Split a time zone name into a 3-tuple of (name, sign, offset).

</patch>
--------------------------------------------------
analyze:
CoT internal conflict:
Ensure correct logger is used: This step requires the use of a suitable logger, but this step still uses a simple logger instead of choosing a dedicated context manager (debug_transaction).

text:
<issue>
Mitigate the BREACH attack
Description

		(last modified by Nick Pope)

The BREACH attack (​https://breachattack.com/) was published in 2013. The Django project responded soon after (​https://www.djangoproject.com/weblog/2013/aug/06/breach-and-django/) suggesting users to basically stop using gzip. CSRF masking was implemented in 2016 (#20869).
In April 2022, a paper called "Heal The Breach" was published, suggesting a mitigation that does not depend on masking specific tokens or injecting data into HTML. It is rather a generic and effective mitigation. It suggests adding randomness to the compressed response by injecting random bytes in the gzip filename field of the gzip stream: ​https://ieeexplore.ieee.org/document/9754554
Telling users to disable gzip is not great for bandwidth consumption. I propose that Django should implement "Heal The Breach" with sensible default.

</issue>

steps:

1. **Import Necessary Modules**: Add imports for `gzip`, `io`, and `get_random_string` to handle GZIP compression and generate random filenames.
2. **Remove Obsolete Imports**: Remove the imports for `compress_sequence` and `compress_string` from `django.utils.text` since we'll handle compression directly.
3. **Modify Streaming Response Handling**: Replace the use of `compress_sequence` with a local function that creates a GZIP file with a random filename for each chunk of streaming content.
4. **Modify Non-Streaming Response Handling**: Replace `compress_string` by directly compressing the content using `GzipFile` with a random filename, ensuring the compressed content is generated with added randomness.
5. **Generate Random Filenames**: Use `get_random_string` to create a 10-character random string for each response's GZIP filename field, introducing entropy to mitigate BREACH.
6. **Adjust Content Handling**: Ensure the new compression methods correctly set the response content and headers, maintaining functionality while enhancing security.

model_patch:

--- a/django/middleware/gzip.py
+++ b/django/middleware/gzip.py
@@ -1,8 +1,11 @@
+import gzip
+import io
 from django.utils.cache import patch_vary_headers
 from django.utils.deprecation import MiddlewareMixin
 from django.utils.regex_helper import _lazy_re_compile
-from django.utils.text import compress_sequence, compress_string
+from django.utils.crypto import get_random_string

+
 re_accepts_gzip = _lazy_re_compile(r"\bgzip\b")


@@ -32,14 +35,30 @@
         if not re_accepts_gzip.search(ae):
             return response

+        def compress_sequence(sequence):
+            buf = io.BytesIO()
+            filename = get_random_string(10)
+            with gzip.GzipFile(mode='wb', compresslevel=6, fileobj=buf, filename=filename, mtime=0) as zfile:
+                for item in sequence:
+                    zfile.write(item)
+                    data = buf.getvalue()
+                    buf.seek(0)
+                    buf.truncate()
+                    yield data
+            remaining = buf.getvalue()
+            if remaining:
+                yield remaining
+
         if response.streaming:
             # Delete the `Content-Length` header for streaming content, because
             # we won't know the compressed size until we stream it.
-            response.streaming_content = compress_sequence(response.streaming_content)
+            response.streaming_content = compress_sequence(response.streaming_content)
             del response.headers["Content-Length"]
         else:
-            # Return the compressed content only if it's actually shorter.
-            compressed_content = compress_string(response.content)
+            filename = get_random_string(10)
+            zbuf = io.BytesIO()
+            with gzip.GzipFile(mode='wb', compresslevel=6, fileobj=zbuf, filename=filename, mtime=0) as zfile:
+                zfile.write(response.content)
+            compressed_content = zbuf.getvalue()
             if len(compressed_content) >= len(response.content):
                 return response
             response.content = compressed_content


gold_patch:
<patch>
diff --git a/django/middleware/gzip.py b/django/middleware/gzip.py
--- a/django/middleware/gzip.py
+++ b/django/middleware/gzip.py
@@ -13,6 +13,8 @@ class GZipMiddleware(MiddlewareMixin):
     on the Accept-Encoding header.
     """

+    max_random_bytes = 100
+
     def process_response(self, request, response):
         # It's not worth attempting to compress really short responses.
         if not response.streaming and len(response.content) < 200:
@@ -31,11 +33,17 @@ def process_response(self, request, response):
         if response.streaming:
             # Delete the `Content-Length` header for streaming content, because
             # we won't know the compressed size until we stream it.
-            response.streaming_content = compress_sequence(response.streaming_content)
+            response.streaming_content = compress_sequence(
+                response.streaming_content,
+                max_random_bytes=self.max_random_bytes,
+            )
             del response.headers["Content-Length"]
         else:
             # Return the compressed content only if it's actually shorter.
-            compressed_content = compress_string(response.content)
+            compressed_content = compress_string(
+                response.content,
+                max_random_bytes=self.max_random_bytes,
+            )
             if len(compressed_content) >= len(response.content):
                 return response
             response.content = compressed_content
diff --git a/django/utils/text.py b/django/utils/text.py
--- a/django/utils/text.py
+++ b/django/utils/text.py
@@ -1,4 +1,6 @@
+import gzip
 import re
+import secrets
 import unicodedata
 from gzip import GzipFile
 from gzip import compress as gzip_compress
@@ -314,8 +316,23 @@ def phone2numeric(phone):
     return "".join(char2number.get(c, c) for c in phone.lower())


-def compress_string(s):
-    return gzip_compress(s, compresslevel=6, mtime=0)
+def _get_random_filename(max_random_bytes):
+    return b"a" * secrets.randbelow(max_random_bytes)
+
+
+def compress_string(s, *, max_random_bytes=None):
+    compressed_data = gzip_compress(s, compresslevel=6, mtime=0)
+
+    if not max_random_bytes:
+        return compressed_data
+
+    compressed_view = memoryview(compressed_data)
+    header = bytearray(compressed_view[:10])
+    header[3] = gzip.FNAME
+
+    filename = _get_random_filename(max_random_bytes) + b"\x00"
+
+    return bytes(header) + filename + compressed_view[10:]


 class StreamingBuffer(BytesIO):
@@ -327,9 +344,12 @@ def read(self):


 # Like compress_string, but for iterators of strings.
-def compress_sequence(sequence):
+def compress_sequence(sequence, *, max_random_bytes=None):
     buf = StreamingBuffer()
-    with GzipFile(mode="wb", compresslevel=6, fileobj=buf, mtime=0) as zfile:
+    filename = _get_random_filename(max_random_bytes) if max_random_bytes else None
+    with GzipFile(
+        filename=filename, mode="wb", compresslevel=6, fileobj=buf, mtime=0
+    ) as zfile:
         # Output headers...
         yield buf.read()
         for item in sequence:

</patch>

--------------------------------------------------
analyze:
The CoT steps are inconsistent with code - the code implementation is too simple:
model_patch directly calls get_random_string(10) to generate a random string of fixed length (10 characters). Although it can increase some randomness, the randomness is fixed and unadjustable. gold_patch introduces the max_random_bytes parameter and generates random bytes through the helper function _get_random_filename(max_random_bytes) (using the secrets module), which can flexibly control the number of random bytes and improve entropy and security. model_patch uses get_random_string to generate random file names. Although it is simple and easy to use, its security and unpredictability may be less than that of using a special random byte generation method. gold_patch uses secrets.randbelowGenerating random bytes is more in line with security requirements and can provide higher quality randomness, thereby more effectively mitigating BREACH attacks.
text:
<issue>
Deprecate passing positional arguments to Signer.
Description

We discovered a vulnerability in one of our applications recently which was caused by an inaccurate instantiation of django.core.signing.Signer. The developer intended to use the user's email address as the salt for the Signing instance but instead caused it to be used as the key. Here's an example code block that demonstrates the problem:
signer = Signer(self.context['request'].user.email)
signed_data = signer.sign_object(dict(
	license_number='...',
	product_id='...',
	device_count='...'
))
In our case, this signed data was then being used to verify a later request and generate an active license. This meant that an attacker could feasibly generate their own licenses if they realised that their email address was the key. The fix for this was to add salt= in front of the email variable. It occurred to us that this is a relatively easy mistake to make and could be avoided if the signature of Signer.__init__ was changed thusly:
- def __init__(self, key=None, sep=':', salt=None, algorithm=None):
+ def __init__(self, *, key=None, sep=':', salt=None, algorithm=None):
That is, adding a * after self to force the developer to name the parameters.

</issue>

steps:

1. Locate the Signer class's __init__ method in django/core/signing.py.
2. Modify the __init__ method's parameter list to include a * after 'self', forcing all subsequent parameters (key, sep, salt, algorithm, fallback_keys) to be keyword-only arguments.
3. This change ensures that positional arguments cannot be used when initializing Signer, preventing accidental misassignment of parameters like key and salt.

model_patch:

--- a/django/core/signing.py
+++ b/django/core/signing.py
@@ -166,6 +166,7 @@
 class Signer:
     def __init__(
         self,
+        *,
         key=None,
         sep=":",
         salt=None,


gold_patch:
<patch>
diff --git a/django/core/signing.py b/django/core/signing.py
--- a/django/core/signing.py
+++ b/django/core/signing.py
@@ -37,10 +37,12 @@
 import datetime
 import json
 import time
+import warnings
 import zlib

 from django.conf import settings
 from django.utils.crypto import constant_time_compare, salted_hmac
+from django.utils.deprecation import RemovedInDjango51Warning
 from django.utils.encoding import force_bytes
 from django.utils.module_loading import import_string
 from django.utils.regex_helper import _lazy_re_compile
@@ -147,7 +149,7 @@ def dumps(

     The serializer is expected to return a bytestring.
     """
-    return TimestampSigner(key, salt=salt).sign_object(
+    return TimestampSigner(key=key, salt=salt).sign_object(
         obj, serializer=serializer, compress=compress
     )

@@ -165,7 +167,9 @@ def loads(

     The serializer is expected to accept a bytestring.
     """
-    return TimestampSigner(key, salt=salt, fallback_keys=fallback_keys).unsign_object(
+    return TimestampSigner(
+        key=key, salt=salt, fallback_keys=fallback_keys
+    ).unsign_object(
         s,
         serializer=serializer,
         max_age=max_age,
@@ -173,8 +177,13 @@ def loads(


 class Signer:
+    # RemovedInDjango51Warning: When the deprecation ends, replace with:
+    # def __init__(
+    #   self, *, key=None, sep=":", salt=None, algorithm=None, fallback_keys=None
+    # ):
     def __init__(
         self,
+        *args,
         key=None,
         sep=":",
         salt=None,
@@ -188,16 +197,29 @@ def __init__(
             else settings.SECRET_KEY_FALLBACKS
         )
         self.sep = sep
-        if _SEP_UNSAFE.match(self.sep):
-            raise ValueError(
-                "Unsafe Signer separator: %r (cannot be empty or consist of "
-                "only A-z0-9-_=)" % sep,
-            )
         self.salt = salt or "%s.%s" % (
             self.__class__.__module__,
             self.__class__.__name__,
         )
         self.algorithm = algorithm or "sha256"
+        # RemovedInDjango51Warning.
+        if args:
+            warnings.warn(
+                f"Passing positional arguments to {self.__class__.__name__} is "
+                f"deprecated.",
+                RemovedInDjango51Warning,
+                stacklevel=2,
+            )
+            for arg, attr in zip(
+                args, ["key", "sep", "salt", "algorithm", "fallback_keys"]
+            ):
+                if arg or attr == "sep":
+                    setattr(self, attr, arg)
+        if _SEP_UNSAFE.match(self.sep):
+            raise ValueError(
+                "Unsafe Signer separator: %r (cannot be empty or consist of "
+                "only A-z0-9-_=)" % sep,
+            )

     def signature(self, value, key=None):
         key = key or self.key

</patch>

--------------------------------------------------
analyze:
Prompt fuzzy --- Missing context information --- Parameter fuzzy
It is reasonable and safe to require developers to use keyword parameters to initialize Signer, but simply adding * to the parameter list (as shown in model_patch) will directly destroy backward compatibility, causing existing codes that use positional parameters to not work properly. Therefore, both CoT and generated code are wrong.

text:
<issue>
Choose which items are displayed per language in Sitemap
Description

The current implementation of Sitemap is : if we use i18n, then we display a cartesian product between some items and some languages.
There is no way to use the provided i18n automation if we want to display some items depending on the language (for instance non-translated blog articles).
I precise in my case, urls are translated, so given a language the url may not exist or raise an error.

</issue>

steps:

1. **Modify the Sitemap's `_items` method** to reverse the order of loops when `i18n` is enabled. Instead of iterating over all languages and then all items, iterate over each item and then the languages applicable to that item. This allows filtering items per language.
2. **Introduce a new method `get_languages_for_item`** in the Sitemap class. This method returns the list of languages for a given item, defaulting to all configured languages. Users can override this method in their sitemap classes to provide language-specific filtering.
3. **Update the list comprehension in `_items`** to use `get_languages_for_item(item)` for each item, ensuring that only valid language-item pairs are included in the sitemap.

model_patch:

--- a/django/contrib/sitemaps/__init__.py
+++ b/django/contrib/sitemaps/__init__.py
@@ -99,14 +99,18 @@
         if self.languages is not None:
             return self.languages
         return [lang_code for lang_code, _ in settings.LANGUAGES]
+
+    def get_languages_for_item(self, item):
+        return self._languages()

     def _items(self):
         if self.i18n:
             # Create (item, lang_code) tuples for all items and languages.
             # This is necessary to paginate with all languages already considered.
             items = [
-                (item, lang_code)
-                for lang_code in self._languages()
-                for item in self.items()
+                (item, lang_code)
+                for item in self.items()
+                for lang_code in self.get_languages_for_item(item)
             ]
             return items
         return self.items()
+


gold_patch:
<patch>
diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py
--- a/django/contrib/sitemaps/__init__.py
+++ b/django/contrib/sitemaps/__init__.py
@@ -92,6 +92,10 @@ def _get(self, name, item, default=None):
             return attr(item)
         return attr

+    def get_languages_for_item(self, item):
+        """Languages for which this item is displayed."""
+        return self._languages()
+
     def _languages(self):
         if self.languages is not None:
             return self.languages
@@ -103,8 +107,8 @@ def _items(self):
             # This is necessary to paginate with all languages already considered.
             items = [
                 (item, lang_code)
-                for lang_code in self._languages()
                 for item in self.items()
+                for lang_code in self.get_languages_for_item(item)
             ]
             return items
         return self.items()
@@ -201,7 +205,8 @@ def _urls(self, page, protocol, domain):
             }

             if self.i18n and self.alternates:
-                for lang_code in self._languages():
+                item_languages = self.get_languages_for_item(item[0])
+                for lang_code in item_languages:
                     loc = f"{protocol}://{domain}{self._location(item, lang_code)}"
                     url_info["alternates"].append(
                         {
@@ -209,7 +214,7 @@ def _urls(self, page, protocol, domain):
                             "lang_code": lang_code,
                         }
                     )
-                if self.x_default:
+                if self.x_default and settings.LANGUAGE_CODE in item_languages:
                     lang_code = settings.LANGUAGE_CODE
                     loc = f"{protocol}://{domain}{self._location(item, lang_code)}"
                     loc = loc.replace(f"/{lang_code}/", "/", 1)

</patch>

--------------------------------------------------
analyze:
Prompt Blur --- Implementing Blur details --- Functional level --- Operation Blur details
The inaccuracy of the description in the background of the problem lies in the statement of the current implementation generation combination method. In the background, it says "If i18n is used, the Cartesian product of some projects and some languages ​​will be displayed", which is easy to misunderstand that only some projects will be combined with some languages.
But in fact, the current implementation will combine all projects with all configured languages, which is why the URL generated in some languages ​​does not exist or goes wrong. Therefore, the problem is that the description of the scope of "Cartesian products" is not accurate enough, which misleads the essence of the actual problem.
text:
<issue>
Admin Site shall filter LogEntries by registered models
Description

This ticket has been discussed here: ​https://groups.google.com/g/django-developers/c/OyTo0P2TfAE
If an implementer registers more than one AdminSite, one might expect that only changes on models registered at that specific site are logged.
This currently is not the case, all registered sites show all entries of LogEntry. It is confusing for users to access a specific site and see log entries for models they can't access.

</issue>

steps:

1. **Import Required Modules**: Add imports for `LogEntry` and `ContentType` to access the necessary models.
2. **Retrieve Registered Models**: Access the models registered with the current AdminSite using `self._registry`.
3. **Fetch Content Types**: Obtain the content types corresponding to the registered models.
4. **Filter Log Entries**: Query the `LogEntry` model to get entries related to the retrieved content types.
5. **Update Context**: Add the filtered LogEntries to the context, which will be used by the admin template to display recent actions.

model_patch:

--- a/django/contrib/admin/sites.py
+++ b/django/contrib/admin/sites.py
@@ -10,6 +10,8 @@
 from django.contrib.admin import ModelAdmin, actions
 from django.contrib.admin.views.autocomplete import AutocompleteJsonView
 from django.contrib.auth import REDIRECT_FIELD_NAME
+from django.contrib.admin.models import LogEntry
+from django.contrib.contenttypes.models import ContentType
 from django.core.exceptions import ImproperlyConfigured
 from django.db.models.base import ModelBase
 from django.http import Http404, HttpResponsePermanentRedirect, HttpResponseRedirect
@@ -550,13 +552,22 @@
         """
         Display the main admin index page, which lists all of the installed
         apps that have been registered in this site.
         """
         app_list = self.get_app_list(request)

+        # Get content types of registered models in this AdminSite
+        registered_models = self._registry.keys()
+        content_types = ContentType.objects.get_for_models(*registered_models).values()
+        content_type_ids = [ct.id for ct in content_types]
+
+        # Fetch recent actions filtered by the content types
+        recent_actions = LogEntry.objects.filter(
+            content_type_id__in=content_type_ids
+        ).select_related('content_type', 'user')[:10]
+
         context = {
             **self.each_context(request),
             "title": self.index_title,
             "subtitle": None,
             "app_list": app_list,
+            "recent_actions": recent_actions,
             **(extra_context or {}),
         }

         request.current_app = self.name


gold_patch:
<patch>
diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py
--- a/django/contrib/admin/sites.py
+++ b/django/contrib/admin/sites.py
@@ -336,6 +336,7 @@ def each_context(self, request):
             "available_apps": self.get_app_list(request),
             "is_popup": False,
             "is_nav_sidebar_enabled": self.enable_nav_sidebar,
+            "log_entries": self.get_log_entries(request),
         }

     def password_change(self, request, extra_context=None):
@@ -588,6 +589,11 @@ def app_index(self, request, app_label, extra_context=None):
             context,
         )

+    def get_log_entries(self, request):
+        from django.contrib.admin.models import LogEntry
+
+        return LogEntry.objects.select_related("content_type", "user")
+

 class DefaultAdminSite(LazyObject):
     def _setup(self):
diff --git a/django/contrib/admin/templatetags/log.py b/django/contrib/admin/templatetags/log.py
--- a/django/contrib/admin/templatetags/log.py
+++ b/django/contrib/admin/templatetags/log.py
@@ -1,5 +1,4 @@
 from django import template
-from django.contrib.admin.models import LogEntry

 register = template.Library()

@@ -12,16 +11,13 @@ def __repr__(self):
         return "<GetAdminLog Node>"

     def render(self, context):
-        if self.user is None:
-            entries = LogEntry.objects.all()
-        else:
+        entries = context["log_entries"]
+        if self.user is not None:
             user_id = self.user
             if not user_id.isdigit():
                 user_id = context[self.user].pk
-            entries = LogEntry.objects.filter(user__pk=user_id)
-        context[self.varname] = entries.select_related("content_type", "user")[
-            : int(self.limit)
-        ]
+            entries = entries.filter(user__pk=user_id)
+        context[self.varname] = entries[: int(self.limit)]
         return ""



</patch>

--------------------------------------------------
analyze:
Prompt Blur --- Implementing Blur details --- Functional level --- Operation Blur details
The assumptions about the LogEntry record range are inaccurate: In the background of the problem, each AdminSite should only display the logs generated by the model it registered, but in fact, LogEntry is a global logging mechanism, and all model changes registered with any AdminSite will be recorded. That is to say, LogEntry does not distinguish records based on which AdminSite is registered, which leads to the expected behavior of "only displaying the logs of this site registration model" in the background that are inconsistent with the actual architecture. The coexistence of models in multiple AdminSites is ignored: If a model is registered with multiple AdminSites, filtering based on the registration situation may cause some legal log records to be mistakenly filtered out in a certain site, and this background description is not taken into account.

